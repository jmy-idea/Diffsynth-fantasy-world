# ğŸ› æ•…éšœæ’æŸ¥ä¸å¸¸è§é—®é¢˜ (FAQ)

åŒ…å«å¸¸è§é”™è¯¯ã€è§£å†³æ–¹æ¡ˆå’Œæœ€ä½³å®è·µã€‚

---

## ğŸ“‹ ç›®å½•

1. [ç¯å¢ƒé—®é¢˜](#ç¯å¢ƒé—®é¢˜)
2. [æ•°æ®ç›¸å…³é—®é¢˜](#æ•°æ®ç›¸å…³é—®é¢˜)
3. [è®­ç»ƒé—®é¢˜](#è®­ç»ƒé—®é¢˜)
4. [æ¨ç†é—®é¢˜](#æ¨ç†é—®é¢˜)
5. [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)
6. [å¸¸è§é—®é¢˜ FAQ](#å¸¸è§é—®é¢˜-faq)

---

## ğŸ”Œ ç¯å¢ƒé—®é¢˜

### E1: CUDA out of memory

**é”™è¯¯ä¿¡æ¯**:
```
RuntimeError: CUDA out of memory. Tried to allocate 2.40 GiB (GPU 0; 40.00 GiB total capacity; ...)
```

**åŸå› **:
- Batch size è¿‡å¤§
- æ¨¡å‹å¤ªå¤§
- GPU è¢«å…¶ä»–è¿›ç¨‹å ç”¨

**è§£å†³**:

```bash
# 1. æ¸…é™¤ç¼“å­˜
python -c "import torch; torch.cuda.empty_cache()"

# 2. æŸ¥çœ‹ GPU å ç”¨
nvidia-smi

# 3. æ€æ­»å…¶ä»–è¿›ç¨‹
kill <PID>

# 4. å‡å° batch size (åœ¨è„šæœ¬ä¸­)
BATCH_SIZE_PER_GPU=4  # ä» 8 æ”¹ä¸º 4
```

**é¢„é˜²**:
- ç›‘æ§æ˜¾å­˜ä½¿ç”¨
- ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯è¡¥å¿
- å¯ç”¨æ··åˆç²¾åº¦ (bf16)

---

### E2: "No module named 'diffsynth'"

**é”™è¯¯ä¿¡æ¯**:
```
ModuleNotFoundError: No module named 'diffsynth'
```

**åŸå› **:
- diffsynth æœªå®‰è£…
- è™šæ‹Ÿç¯å¢ƒæœªæ¿€æ´»
- PYTHONPATH æœªè®¾ç½®

**è§£å†³**:

```bash
# 1. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
which python

# 2. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source ~/envs/fantasy_world/bin/activate

# 3. é‡æ–°å®‰è£…
cd /ML-vePFS/research_gen/jmy/jmy_ws/Diffsynth-fantasy-world
pip install -e .

# 4. éªŒè¯
python -c "import diffsynth; print('OK')"
```

---

### E3: "CUDA is not available"

**é”™è¯¯ä¿¡æ¯**:
```
torch.cuda.is_available() returns False
```

**åŸå› **:
- é©±åŠ¨ä¸åŒ¹é…
- CUDA ç‰ˆæœ¬é—®é¢˜
- PyTorch æœªæ­£ç¡®å®‰è£…

**è§£å†³**:

```bash
# 1. æ£€æŸ¥é©±åŠ¨
nvidia-smi  # åº”è¯¥æ˜¾ç¤º GPU ä¿¡æ¯

# 2. æ£€æŸ¥ CUDA
nvcc --version  # åº”è¯¥æ˜¾ç¤º CUDA ç‰ˆæœ¬

# 3. é‡è£… PyTorch (é’ˆå¯¹æ­£ç¡®çš„ CUDA ç‰ˆæœ¬)
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 4. éªŒè¯
python << 'EOF'
import torch
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"CUDA Version: {torch.version.cuda}")
EOF
```

---

## ğŸ“Š æ•°æ®ç›¸å…³é—®é¢˜

### D1: "æ•°æ®é›†éªŒè¯å¤±è´¥"

**é”™è¯¯ä¿¡æ¯**:
```
Error: Metadata not found or invalid format
```

**åŸå› **:
- metadata.json ç¼ºå¤±æˆ–æ ¼å¼é”™è¯¯
- æ–‡ä»¶è·¯å¾„ä¸æ­£ç¡®
- æ•°æ®æ–‡ä»¶æŸå

**è§£å†³**:

```bash
# 1. æ£€æŸ¥æ–‡ä»¶å­˜åœ¨
ls fantasy_world_dataset/metadata.json

# 2. éªŒè¯ JSON æ ¼å¼
python -c "import json; json.load(open('metadata.json'))"

# 3. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
python << 'EOF'
import json
import os

with open("fantasy_world_dataset/metadata.json") as f:
    metadata = json.load(f)

for sample in metadata['samples']:
    sample_dir = f"fantasy_world_dataset/{sample['id']}"
    
    # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
    video = os.path.join(sample_dir, sample['video_path'])
    if not os.path.exists(video):
        print(f"âŒ {sample['id']}: è§†é¢‘æ–‡ä»¶ç¼ºå¤±")
    
    # æ£€æŸ¥æ·±åº¦å›¾æ•°é‡
    depth_dir = os.path.join(sample_dir, sample['depth_dir'])
    depth_files = [f for f in os.listdir(depth_dir) if f.endswith('.npy')]
    if len(depth_files) != sample['num_frames']:
        print(f"âš ï¸ {sample['id']}: æ·±åº¦å›¾æ•°é‡ä¸åŒ¹é…")

print("âœ… éªŒè¯å®Œæˆ")
EOF
```

---

### D2: "æ·±åº¦å›¾å€¼åŸŸå¼‚å¸¸"

**ç—‡çŠ¶**:
```
Warning: Depth values outside expected range (max=255.0, expected <= 1.0)
```

**åŸå› **:
- æ·±åº¦å›¾æœªå½’ä¸€åŒ–
- ç”Ÿæˆå·¥å…·è¾“å‡ºæ ¼å¼ä¸åŒ

**è§£å†³**:

```python
import numpy as np
import os

depth_dir = "fantasy_world_dataset/sample_001/depth"

for file in os.listdir(depth_dir):
    if not file.endswith('.npy'):
        continue
    
    depth = np.load(os.path.join(depth_dir, file))
    
    # å¦‚æœå€¼åœ¨ 0-255 èŒƒå›´ï¼Œè½¬æ¢ä¸º 0-1
    if depth.max() > 1.5:
        depth = depth / 255.0
        np.save(os.path.join(depth_dir, file), depth)
        print(f"å·²ä¿®å¤: {file}")
```

---

### D3: "ç‚¹äº‘åŒ…å« NaN"

**ç—‡çŠ¶**:
```
Warning: NaN values detected in point cloud
```

**åŸå› **:
- ç‚¹äº‘ä¼°è®¡å¤±è´¥
- æ–‡ä»¶æŸå

**è§£å†³**:

```python
import numpy as np
import os

def clean_points(points_dir):
    for file in os.listdir(points_dir):
        if not file.endswith('.npy'):
            continue
        
        points = np.load(os.path.join(points_dir, file))
        
        # æ£€æŸ¥å¹¶æ›¿æ¢ NaN
        if np.isnan(points).any():
            print(f"âš ï¸ {file} åŒ…å« NaNï¼Œæ­£åœ¨ä¿®å¤...")
            # é€‰é¡¹ 1: æ›¿æ¢ä¸º 0
            points = np.nan_to_num(points, nan=0.0)
            # é€‰é¡¹ 2: ä½¿ç”¨ä¸­å€¼
            # points[np.isnan(points)] = np.nanmedian(points)
            np.save(os.path.join(points_dir, file), points)

clean_points("fantasy_world_dataset/sample_001/points")
```

---

## ğŸ“ è®­ç»ƒé—®é¢˜

### T1: "Loss ä¸ä¸‹é™æˆ–åå‘å¢é•¿"

**ç—‡çŠ¶**:
```
Step 1000: loss = 1.5
Step 2000: loss = 1.7
Step 3000: loss = 2.0
```

**åŸå› **:
- å­¦ä¹ ç‡è¿‡é«˜
- æ•°æ®è´¨é‡é—®é¢˜
- æ¨¡å‹æ¶æ„é”™è¯¯

**è§£å†³**:

```bash
# 1. é™ä½å­¦ä¹ ç‡
LEARNING_RATE=5e-6  # ä» 1e-5 æ”¹ä¸º 5e-6

# 2. æ£€æŸ¥æ•°æ®
python scripts/verify_dataset.py --dataset_path fantasy_world_dataset

# 3. æ£€æŸ¥æ¨¡å‹åˆå§‹åŒ–
python << 'EOF'
import torch
from diffsynth import WanVideoPipeline

pipe = WanVideoPipeline.from_pretrained(...)
pipe.dit.enable_fantasy_world_mode()

# è¾“å‡ºåˆå§‹ loss
x = torch.randn(1, 81, 1536)
# ... è®¡ç®— loss
EOF
```

---

### T2: "Loss éœ‡è¡ä¸æ”¶æ•›"

**ç—‡çŠ¶**:
```
Step 5000: loss = 0.15
Step 5100: loss = 0.25
Step 5200: loss = 0.12
```

**åŸå› **:
- å­¦ä¹ ç‡è°ƒåº¦ä¸å½“
- Batch size è¿‡å°
- æ¢¯åº¦ä¸ç¨³å®š

**è§£å†³**:

```bash
# 1. å¯ç”¨å­¦ä¹ ç‡é¢„çƒ­
# åœ¨è®­ç»ƒè„šæœ¬ä¸­é…ç½® warmup

# 2. å¢åŠ  batch size
BATCH_SIZE_PER_GPU=8  # ä» 4 æ”¹ä¸º 8

# 3. å¯ç”¨æ¢¯åº¦è£å‰ª
# åœ¨ä¼˜åŒ–å™¨ä¸­è®¾ç½® max_grad_norm=1.0
```

---

### T3: "DDP æŠ¥é”™: 'unused parameters'"

**é”™è¯¯**:
```
RuntimeError: Expected to have finished reduction in the backward pass before final callback...
```

**åŸå› **:
- Stage 1 ä¸­æŸäº›æ¨¡å—å†»ç»“
- DDP ä¸çŸ¥é“å‚æ•°ä¸éœ€è¦æ¢¯åº¦

**è§£å†³**:

```bash
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ 
--find_unused_parameters

# åœ¨ train.py ä¸­
model = torch.nn.parallel.DistributedDataParallel(
    model,
    find_unused_parameters=True  # å…³é”®
)
```

---

### T4: "æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥"

**é”™è¯¯**:
```
KeyError: 'expected key not found in checkpoint'
```

**åŸå› **:
- æ£€æŸ¥ç‚¹æ¶æ„ä¸åŒ¹é…
- æ¨¡å—å‘½åä¸ä¸€è‡´

**è§£å†³**:

```python
import torch

# ä½¿ç”¨ strict=False å…è®¸ä¸åŒ¹é…
checkpoint = torch.load("checkpoint.pt", map_location="cpu")
model.load_state_dict(checkpoint, strict=False)

# æ£€æŸ¥ç¼ºå¤±çš„é”®
model_keys = set(model.state_dict().keys())
checkpoint_keys = set(checkpoint.keys())

missing = model_keys - checkpoint_keys
extra = checkpoint_keys - model_keys

print(f"ç¼ºå¤±é”®: {len(missing)}")
print(f"é¢å¤–é”®: {len(extra)}")
```

---

## ğŸ¬ æ¨ç†é—®é¢˜

### I1: "æ¨ç†è¾“å‡ºå…¨é»‘"

**ç—‡çŠ¶**:
```
è¾“å‡ºè§†é¢‘å®Œå…¨é»‘è‰²æˆ–æ— æ•ˆ
```

**åŸå› **:
- æ£€æŸ¥ç‚¹åŠ è½½é”™è¯¯
- æ¨¡å‹æœªæ­£ç¡®åˆå§‹åŒ–

**è§£å†³**:

```python
import torch
from diffsynth import WanVideoPipeline

# éªŒè¯æ£€æŸ¥ç‚¹
checkpoint = torch.load("checkpoint.pt", map_location="cpu")
print(f"æ£€æŸ¥ç‚¹å¤§å°: {len(checkpoint)} é”®")
print(f"é¦–ä¸ªé”®: {list(checkpoint.keys())[0]}")

# é‡æ–°åŠ è½½
pipe = WanVideoPipeline.from_pretrained(...)
pipe.dit.enable_fantasy_world_mode(training_stage="stage2")
state_dict = torch.load("checkpoint.pt", map_location="cpu")
pipe.dit.load_state_dict(state_dict, strict=False)

# æµ‹è¯•ç®€å•æ¨ç†
video = pipe(prompt="test", num_frames=21, num_inference_steps=10)
print(f"è§†é¢‘èŒƒå›´: {video.min():.3f} ~ {video.max():.3f}")
assert video.max() > 0, "è§†é¢‘ä¸ºé›¶"
```

---

### I2: "å†…å­˜ä¸è¶³ (æ¨ç†æ—¶)"

**ç—‡çŠ¶**:
```
CUDA out of memory during inference
```

**åŸå› **:
- åˆ†è¾¨ç‡è¿‡é«˜
- å¸§æ•°è¿‡å¤š
- æ¨ç†æ­¥æ•°è¿‡å¤š

**è§£å†³**:

```python
# æ–¹æ¡ˆ 1: é™ä½åˆ†è¾¨ç‡
video = pipe(
    prompt="...",
    num_frames=41,  # ä» 81 æ”¹ä¸º 41
    height=224,     # ä» 336 æ”¹ä¸º 224
    width=384       # ä» 592 æ”¹ä¸º 384
)

# æ–¹æ¡ˆ 2: å¯ç”¨å†…å­˜ä¼˜åŒ–
pipe.enable_attention_slicing()
pipe.enable_model_cpu_offload()

# æ–¹æ¡ˆ 3: å‡å°‘æ¨ç†æ­¥æ•°
video = pipe(
    prompt="...",
    num_inference_steps=30  # ä» 50 æ”¹ä¸º 30
)
```

---

### I3: "æ¨ç†é€Ÿåº¦å¾ˆæ…¢"

**ç—‡çŠ¶**:
```
æ¯å¸§éœ€è¦ 2-3 ç§’ï¼Œ81 å¸§éœ€è¦ 3-4 åˆ†é’Ÿ
```

**åŸå› **:
- æ¨ç†æ­¥æ•°è¿‡å¤š
- æœªå¯ç”¨ä¼˜åŒ–

**è§£å†³**:

```python
# 1. å‡å°‘æ¨ç†æ­¥æ•°
num_steps = 30  # æ¨è 30-50

# 2. å¯ç”¨ä¼˜åŒ–
import torch
from diffsynth import WanVideoPipeline

pipe = WanVideoPipeline.from_pretrained(
    ...,
    torch_dtype=torch.float16  # ä½¿ç”¨ float16 åŠ å¿«é€Ÿåº¦
)
pipe.enable_xformers_memory_efficient_attention()

# 3. ä½¿ç”¨æ›´å¿«çš„ scheduler
from diffusers import EulerDiscreteScheduler
pipe.scheduler = EulerDiscreteScheduler.from_config(...)

# é¢„æœŸé€Ÿåº¦: 50-100 ms/step, æ€»å…± 1-2 åˆ†é’Ÿ
```

---

## âš¡ æ€§èƒ½é—®é¢˜

### P1: "GPU åˆ©ç”¨ç‡ä½"

**ç—‡çŠ¶**:
```
nvidia-smi æ˜¾ç¤º GPU å ç”¨ < 50%
```

**åŸå› **:
- Batch size è¿‡å°
- æ•°æ®åŠ è½½é€Ÿåº¦æ…¢

**è§£å†³**:

```bash
# 1. å¢åŠ  batch size
BATCH_SIZE_PER_GPU=16  # ä» 8 æ”¹ä¸º 16

# 2. å¢åŠ  num_workers
--num_workers 8

# 3. å¯ç”¨ pin_memory
# åœ¨æ•°æ®åŠ è½½å™¨ä¸­: pin_memory=True
```

---

### P2: "è®­ç»ƒé€Ÿåº¦æ…¢äºé¢„æœŸ"

**ç—‡çŠ¶**:
```
å®é™…: 5 æ ·æœ¬/ç§’
é¢„æœŸ: 20+ æ ·æœ¬/ç§’
```

**åŸå› **:
- GPU åˆ©ç”¨ç‡ä½
- I/O ç“¶é¢ˆ

**è§£å†³**:

```bash
# 1. ç›‘æ§ GPU ä½¿ç”¨
watch -n 1 nvidia-smi

# 2. æ£€æŸ¥æ•°æ®åŠ è½½æ—¶é—´
python << 'EOF'
import time
from torch.utils.data import DataLoader

loader = DataLoader(dataset, batch_size=64, num_workers=8)

for i, batch in enumerate(loader):
    if i == 0:
        # ç¬¬ä¸€ä¸ª batch çš„æ—¶é—´åŒ…æ‹¬åˆå§‹åŒ–
        continue
    
    start = time.time()
    # æ¨¡å‹å‰å‘ä¼ æ’­
    time_forward = time.time() - start
    
    if i > 10:
        break

print(f"å¹³å‡æ—¶é—´: {time_forward:.3f}s/batch")
EOF

# 3. ä½¿ç”¨ SSD è€Œä¸æ˜¯ HDD
```

---

### P3: "æ˜¾å­˜å ç”¨è¿‡å¤š"

**ç—‡çŠ¶**:
```
nvidia-smi æ˜¾ç¤ºä½¿ç”¨ 35-40GB (æ¥è¿‘ä¸Šé™)
```

**åŸå› **:
- Batch size è¿‡å¤§
- æ¢¯åº¦ç§¯ç´¯

**è§£å†³**:

```bash
# 1. ä½¿ç”¨æ··åˆç²¾åº¦ (æ¨è)
MIXED_PRECISION="bf16"

# 2. å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
# åœ¨æ¨¡å‹ä¸­: model.gradient_checkpointing_enable()

# 3. å¯ç”¨åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œçš„æ¢¯åº¦åŒæ­¥ä¼˜åŒ–
# åœ¨ DDP ä¸­: gradient_as_bucket_view=True
```

---

## â“ å¸¸è§é—®é¢˜ FAQ

### Q1: è®­ç»ƒéœ€è¦å¤šé•¿æ—¶é—´ï¼Ÿ

**A**: 
- Stage 1: ~36 å°æ—¶ (8 Ã— H20, 20K steps)
- Stage 2: ~144 å°æ—¶ (8 Ã— H20, 10K steps)
- æ€»è®¡: 180 å°æ—¶ (7.5 å¤© GPU æ—¶é—´)

å®é™…å¢™é’Ÿæ—¶é—´å–å†³äºé˜Ÿåˆ—ç­‰å¾…æ—¶é—´ã€‚

---

### Q2: å¯ä»¥ç”¨æ›´å°‘çš„ GPU è®­ç»ƒå—ï¼Ÿ

**A**: å¯ä»¥ï¼Œä½†éœ€è¦è°ƒæ•´å‚æ•°ï¼š

```bash
# 4 Ã— GPU (è€Œé 8 Ã—)
BATCH_SIZE_PER_GPU=16  # 4 Ã— 16 = 64 (ä¿æŒå…¨å±€ batch)
GRADIENT_ACCUMULATION=1

# é¢„æœŸæ—¶é—´: 36 Ã— 2 = 72 å°æ—¶ (ç¿»å€)
```

---

### Q3: å¯ä»¥åœ¨ Google Colab ä¸Šè®­ç»ƒå—ï¼Ÿ

**A**: å¯ä»¥è¿›è¡Œæ¨ç†ï¼Œä½†ä¸èƒ½è®­ç»ƒï¼š
- Colab GPU: å•ä¸ª T4 (16GB) æˆ– A100 (40GB)
- éœ€è¦: 8 Ã— GPU

**æ›¿ä»£æ–¹æ¡ˆ**:
- Google Cloud TPU
- AWS æˆ– Azure
- Lambda Labs
- æœ¬åœ° GPU æœåŠ¡å™¨

---

### Q4: å¦‚ä½•ä»ä¸­æ–­çš„ä½ç½®ç»§ç»­è®­ç»ƒï¼Ÿ

**A**:

```bash
# æœ€æ–°æ£€æŸ¥ç‚¹ä¼šè‡ªåŠ¨ä¿å­˜åˆ° latest.safetensors
# æ·»åŠ  resume å‚æ•°ç»§ç»­è®­ç»ƒ

--resume_from_checkpoint ./outputs/fantasy_world_stage1/latest.safetensors
```

---

### Q5: Stage 1 å’Œ Stage 2 éƒ½éœ€è¦å—ï¼Ÿ

**A**: æ˜¯çš„ã€‚åŸå› ï¼š
- Stage 1: è®©å‡ ä½•åˆ†æ”¯é€‚é…åˆ°ç¨³å®šçš„è§†é¢‘ç‰¹å¾
- Stage 2: æ·»åŠ äº¤äº’æ¨¡å—ä»¥æ”¹è¿›è´¨é‡

ç›´æ¥ç”¨ Stage 2 ä¼šä¸æ”¶æ•›ã€‚

---

### Q6: å¯ä»¥å¾®è°ƒé¢„è®­ç»ƒçš„æ¨¡å‹å—ï¼Ÿ

**A**: æ˜¯çš„ï¼Œæœ‰ä¸¤ç§æ–¹å¼ï¼š

**æ–¹å¼ 1: ç»§ç»­è®­ç»ƒ**
```bash
--resume_from_checkpoint outputs/fantasy_world_stage2/step-10000.safetensors
--num_steps 5000  # é¢å¤– 5K æ­¥
```

**æ–¹å¼ 2: LoRA å¾®è°ƒ** (éœ€è¦é¢å¤–å®ç°)
```
ä½¿ç”¨ LoRA åœ¨ç°æœ‰æƒé‡ä¸Šè¿›è¡Œä½ç§©è°ƒæ•´
```

---

### Q7: æ¨ç†éœ€è¦ä»€ä¹ˆç¡¬ä»¶ï¼Ÿ

**A**:
- æœ€ä½: ä»»ä½• 12GB+ VRAM çš„ GPU
- æ¨è: RTX 3090 æˆ– A6000
- æ—¶é—´: 1-2 åˆ†é’Ÿ / è§†é¢‘ (81 å¸§)

å¯åœ¨ CPU ä¸Šè¿è¡Œï¼Œä½†ä¼šéå¸¸æ…¢ (10-20 åˆ†é’Ÿ)ã€‚

---

### Q8: å¦‚ä½•æ”¹è¿›ç”Ÿæˆè´¨é‡ï¼Ÿ

**A**:

| æ–¹æ³• | æ•ˆæœ | æˆæœ¬ |
|------|------|------|
| å¢åŠ  inference steps | é«˜ | æ—¶é—´ç¿»å€ |
| æ”¹è¿›æç¤ºè¯ | ä¸­ç­‰ | å…è´¹ |
| å¢åŠ æ•°æ®è®­ç»ƒ | é«˜ | 200+ å°æ—¶ GPU |
| è°ƒæ•´ guidance scale | ä½ | å…è´¹ |
| ä½¿ç”¨æ›´å¥½çš„åˆå§‹åŒ– | ä¸­ç­‰ | éœ€è¦ä¿®æ”¹ä»£ç  |

---

### Q9: æ”¯æŒå“ªäº›æ•°æ®æ ¼å¼ï¼Ÿ

**A**:
- è§†é¢‘: MP4, AVI, MOV, WebM
- æ·±åº¦å›¾: NPY æ ¼å¼
- ç‚¹äº‘: NPY æ ¼å¼
- ç›¸æœº: TXT æ ¼å¼ (19-value)

è¯¦è§ [æ•°æ®å‡†å¤‡](./DATA_PREPARATION.md)

---

### Q10: å¦‚ä½•æ‰©å±•æ¨¡å‹åˆ°æ›´å¤šåŠŸèƒ½ï¼Ÿ

**A**:

ç›®å‰ Fantasy World æ”¯æŒï¼š
- âœ… æ–‡æœ¬åˆ°è§†é¢‘
- âœ… ç›¸æœºæ§åˆ¶
- âœ… æ·±åº¦é¢„æµ‹
- âœ… ç‚¹äº‘ä¼°è®¡

å¯èƒ½çš„æ‰©å±•ï¼š
- ğŸ“ å›¾åƒé©±åŠ¨
- ğŸ“ æ›´å¤šå‡ ä½•è¾“å‡º (æ³•çº¿, å®ä¾‹åˆ†å‰²)
- ğŸ“ éŸ³é¢‘åŒæ­¥ç”Ÿæˆ

éœ€è¦ä¿®æ”¹ [æ¶æ„](./ARCHITECTURE.md)

---

## ğŸ†˜ å¦‚ä½•è·å–å¸®åŠ©

å¦‚ä»¥ä¸Šä¿¡æ¯æœªèƒ½è§£å†³é—®é¢˜ï¼š

1. **æ£€æŸ¥æ—¥å¿—**: `cat outputs/fantasy_world_stage1/training.log`
2. **æŸ¥çœ‹ä»£ç **: ç›¸å…³æ–‡ä»¶ä½ç½®è§ [æ¶æ„](./ARCHITECTURE.md)
3. **è¿è¡Œè¯Šæ–­**: `python scripts/diagnose.py`
4. **æœç´¢ç›¸ä¼¼é—®é¢˜**: é¡¹ç›®æ–‡æ¡£ä¸­å…¶ä»–éƒ¨åˆ†
5. **ç¤¾åŒºæ”¯æŒ**: DiffSynth-Studio å®˜æ–¹ä»“åº“

---

**ç¥ä½ ä½¿ç”¨é¡ºåˆ©ï¼** ğŸš€
