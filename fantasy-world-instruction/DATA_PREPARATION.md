# ğŸ“Š æ•°æ®å‡†å¤‡ä¸å¤„ç†å®Œå…¨æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•ä¸º Fantasy World æ¨¡å‹å‡†å¤‡è®­ç»ƒå’Œæ¨ç†æ‰€éœ€çš„æ•°æ®ã€‚

---

## ğŸ“‹ ç›®å½•

1. [æ•°æ®éœ€æ±‚æ¦‚è§ˆ](#æ•°æ®éœ€æ±‚æ¦‚è§ˆ)
2. [æ•°æ®æ ¼å¼è§„èŒƒ](#æ•°æ®æ ¼å¼è§„èŒƒ)
3. [æ•°æ®ç”Ÿæˆç®¡é“](#æ•°æ®ç”Ÿæˆç®¡é“)
4. [æ•°æ®é›†ç»„ç»‡ç»“æ„](#æ•°æ®é›†ç»„ç»‡ç»“æ„)
5. [å…ƒæ•°æ®é…ç½®](#å…ƒæ•°æ®é…ç½®)
6. [æ•°æ®éªŒè¯ä¸è´¨é‡æ£€æŸ¥](#æ•°æ®éªŒè¯ä¸è´¨é‡æ£€æŸ¥)
7. [å¸¸è§æ•°æ®é—®é¢˜è§£å†³](#å¸¸è§æ•°æ®é—®é¢˜è§£å†³)

---

## ğŸ“¦ æ•°æ®éœ€æ±‚æ¦‚è§ˆ

### æ€»ä½“éœ€æ±‚

| ç”¨é€” | æœ€å°‘æ•°æ®é‡ | æ¨èæ•°æ®é‡ | å­˜å‚¨ç©ºé—´ |
|------|-----------|-----------|---------|
| **æ¨ç†æµ‹è¯•** | ç¤ºä¾‹å›¾ç‰‡ (è‡ªåŠ¨ä¸‹è½½) | - | 100MB |
| **è®­ç»ƒ** (å®Œæ•´) | 100 ä¸ªæ ·æœ¬ | 1000+ ä¸ªæ ·æœ¬ | 500GB+ |
| **å¾®è°ƒ** | 50 ä¸ªæ ·æœ¬ | 200-500 ä¸ªæ ·æœ¬ | 100-200GB |

### æ¯ä¸ªæ ·æœ¬åŒ…å«

```
sample_001/
â”œâ”€â”€ video.mp4                    # åŸå§‹è§†é¢‘ (å¿…éœ€)
â”œâ”€â”€ depth/                       # æ·±åº¦å›¾åºåˆ— (å¿…éœ€)
â”‚   â”œâ”€â”€ frame_0000.npy
â”‚   â”œâ”€â”€ frame_0001.npy
â”‚   â””â”€â”€ ...
â”œâ”€â”€ points/                      # ç‚¹äº‘åºåˆ— (å¿…éœ€)
â”‚   â”œâ”€â”€ frame_0000.npy
â”‚   â”œâ”€â”€ frame_0001.npy
â”‚   â””â”€â”€ ...
â””â”€â”€ camera_params.txt            # ç›¸æœºè½¨è¿¹ (å¿…éœ€)
```

### æ•°æ®ç‰¹æ€§

| æŒ‡æ ‡ | è¦æ±‚ | è¯´æ˜ |
|------|------|------|
| è§†é¢‘åˆ†è¾¨ç‡ | 336Ã—592 - 592Ã—336 | ä¸åŒé˜¶æ®µå¯èƒ½ä¸åŒ |
| å¸§æ•° | 21-81 | Stage 1 å¯ç”¨ 21 å¸§ï¼ŒStage 2 ä½¿ç”¨ 81 å¸§ |
| å¸§ç‡ | 10-30 fps | å¯¹æ•°æ®è´¨é‡å½±å“ä¸å¤§ |
| ç¼–ç  | H.264/H.265 | å¸¸è§è§†é¢‘ç¼–ç  |
| é¢œè‰²ç©ºé—´ | RGB | éœ€è¦è½¬æ¢åˆ° RGB |
| æ·±åº¦èŒƒå›´ | 0.1-100m | å–å†³äºåœºæ™¯å°ºåº¦ |

---

## ğŸ“ æ•°æ®æ ¼å¼è§„èŒƒ

### 1. è§†é¢‘æ ¼å¼

**è¾“å…¥**: MP4, AVI, MOV, WebM ç­‰å¸¸è§æ ¼å¼

**å¤„ç†æ­¥éª¤**:
```python
# ä½¿ç”¨ OpenCV æˆ– ffmpeg è¯»å–
import cv2
cap = cv2.VideoCapture("video.mp4")
frames = []
while True:
    ret, frame = cap.read()
    if not ret:
        break
    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  # BGR â†’ RGB
    frames.append(frame)  # [H, W, 3]
cap.release()
```

**è¾“å‡º**: å¸§åˆ—è¡¨ï¼Œæ¯å¸§ [H, W, 3] (0-255 uint8 æˆ– 0-1 float32)

### 2. æ·±åº¦å›¾æ ¼å¼

**ç”Ÿæˆå·¥å…·**: Depth Anything V2

**æ ¼å¼è§„èŒƒ**:
- ç±»å‹: `.npy` (numpy æ ¼å¼)
- å€¼åŸŸ: 0-1 (å½’ä¸€åŒ–) æˆ– 0-255 (åŸå§‹)
- å½¢çŠ¶: [H, W] (å•é€šé“)
- æ•°æ®ç±»å‹: float32 æˆ– uint8

**ä¿å­˜æ–¹å¼**:
```python
import numpy as np

# ç”Ÿæˆæˆ–è·å–æ·±åº¦å›¾
depth = np.random.rand(H, W).astype(np.float32)

# ä¿å­˜
np.save("frame_0000.npy", depth)

# åŠ è½½
depth_loaded = np.load("frame_0000.npy")  # [H, W]
```

**é¢„å¤„ç†**:
```python
# å¦‚æœå€¼åŸŸä¸æ˜¯ 0-1ï¼Œè¿›è¡Œå½’ä¸€åŒ–
def normalize_depth(depth):
    min_val = depth.min()
    max_val = depth.max()
    if max_val > min_val:
        depth = (depth - min_val) / (max_val - min_val)
    return depth
```

### 3. ç‚¹äº‘æ ¼å¼

**ç”Ÿæˆå·¥å…·**: DUSt3R / CUT3R æˆ–å…¶ä»– MVS æ–¹æ³•

**æ ¼å¼è§„èŒƒ**:
- ç±»å‹: `.npy` (numpy æ ¼å¼)
- å€¼åŸŸ: -1 åˆ° 1 (å½’ä¸€åŒ–) æˆ–å®é™…å°ºåº¦
- å½¢çŠ¶: [H, W, 3] (XYZ åæ ‡)
- æ•°æ®ç±»å‹: float32

**ç»“æ„**:
```python
# ç‚¹äº‘æ˜¯ä¸€ä¸ª 3D åæ ‡ç½‘æ ¼
points = np.random.randn(H, W, 3).astype(np.float32)
# å¯¹åº”å›¾åƒçš„æ¯ä¸ªåƒç´  (i, j)ï¼Œæœ‰ä¸€ä¸ª 3D ç‚¹ (x, y, z)
```

**ä¿å­˜æ–¹å¼**:
```python
import numpy as np

# ä¿å­˜
np.save("frame_0000.npy", points)

# åŠ è½½
points_loaded = np.load("frame_0000.npy")  # [H, W, 3]
```

**é¢„å¤„ç†** (å½’ä¸€åŒ–):
```python
def normalize_points(points):
    # è®¡ç®—ä¸­å¿ƒ
    center = points.mean(axis=(0, 1))
    points = points - center
    
    # è®¡ç®—å°ºåº¦
    scale = np.abs(points).max()
    if scale > 0:
        points = points / scale
    
    return points
```

### 4. ç›¸æœºå‚æ•°æ ¼å¼

è¿™é‡Œå®é™…ä¸Šå‰é¢7ç»´ä¿æŒ" 0 0.532139961 0.946026558 0.5 0.5 0 0 "å³å¯ï¼Œåªéœ€è¦è·å¾—åé¢12ç»´çš„w2cå¤–å‚ã€‚å‚è€ƒDiffsynth-fantasy-world/Move_Left.txt

**æ ¼å¼**: 19 å€¼ per frame

```
frame_idx fx fy cx cy k1 k2 w2c_00 w2c_01 ... w2c_23

å…¶ä¸­:
- frame_idx: å¸§å· (0-T)
- fx, fy: ç„¦è· (å†…å‚)
- cx, cy: ä¸»ç‚¹ (å†…å‚)
- k1, k2: å¾„å‘ç•¸å˜ç³»æ•°
- w2c_00...w2c_23: ä¸–ç•Œåˆ°ç›¸æœºçš„ 3Ã—4 å˜æ¢çŸ©é˜µ (è¡Œä¼˜å…ˆ)
```

**æ–‡ä»¶æ ¼å¼**: `.txt` æ–‡ä»¶ï¼Œæ¯è¡Œä¸€å¸§

```
0 500.0 500.0 320.0 240.0 0.0 0.0 0.9 0.1 0.2 1.0 0.3 -0.5 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2
1 500.0 500.0 320.0 240.0 0.0 0.0 0.85 0.12 0.25 1.1 ...
...
```

**ç¤ºä¾‹ä»£ç **:

```python
def save_camera_trajectory(frames, cameras, output_file):
    """
    Args:
        frames: å¸§åˆ—è¡¨ (æˆ–å¸§æ•°)
        cameras: Camera å¯¹è±¡åˆ—è¡¨
        output_file: è¾“å‡º txt æ–‡ä»¶
    """
    with open(output_file, 'w') as f:
        for idx, camera in enumerate(cameras):
            # å†…å‚
            fx, fy = camera.intrinsics['fx'], camera.intrinsics['fy']
            cx, cy = camera.intrinsics['cx'], camera.intrinsics['cy']
            
            # ç•¸å˜
            k1, k2 = 0.0, 0.0  # å¦‚æ— ç•¸å˜ä¿¡æ¯ï¼Œè®¾ä¸º 0
            
            # å¤–å‚ (w2c 3Ã—4 çŸ©é˜µï¼Œè¡Œä¼˜å…ˆ)
            w2c = camera.w2c.flatten().tolist()  # [12 values]
            
            # å†™å…¥ä¸€è¡Œ
            line = f"{idx} {fx} {fy} {cx} {cy} {k1} {k2} " + " ".join(map(str, w2c))
            f.write(line + "\n")

def load_camera_trajectory(camera_file):
    """è¯»å–ç›¸æœºè½¨è¿¹æ–‡ä»¶"""
    cameras = []
    with open(camera_file, 'r') as f:
        for line in f:
            values = list(map(float, line.strip().split()))
            
            # è§£æ
            frame_idx = int(values[0])
            fx, fy, cx, cy = values[1:5]
            k1, k2 = values[5:7]
            w2c_flat = values[7:19]
            
            # é‡ç»„ w2c çŸ©é˜µ (3Ã—4)
            w2c = np.array(w2c_flat).reshape(3, 4)
            
            camera = Camera(
                frame_idx=frame_idx,
                intrinsics={'fx': fx, 'fy': fy, 'cx': cx, 'cy': cy},
                distortion={'k1': k1, 'k2': k2},
                w2c=w2c
            )
            cameras.append(camera)
    
    return cameras
```

**è·å–ç›¸æœºå‚æ•°**:

ç›¸æœºå‚æ•°é€šå¸¸æ¥è‡ªï¼š
1. **DUSt3R** : ä»å¤šè§†å›¾é‡å»ºå¾—åˆ°
2. **ViPE** : ç°åœ¨å·²æœ‰æ­¤pipeline
3. **COLMAP**: ç»“æ„å…‰é‡å»ºå·¥å…·
4. **æ‰‹åŠ¨æ ‡æ³¨**: å¦‚æœæœ‰å¤–å‚è®¾å¤‡
5. **ä¼°è®¡**: ä» MVS ç»“æœåæ¨

---

## ğŸ”„ æ•°æ®ç”Ÿæˆç®¡é“

### å®Œæ•´æµç¨‹

```
åŸå§‹è§†é¢‘
    â†“
1. æå–å¸§ (ffmpeg)
    â†“
2. ç”Ÿæˆæ·±åº¦å›¾ (Depth Anything V2)
    â†“
3. ä¼°è®¡ç‚¹äº‘ (DUSt3R)
    â†“
4. ä¼°è®¡ç›¸æœºå‚æ•° (COLMAP æˆ– DUSt3R)
    â†“
5. æ•°æ®ç»„ç»‡ä¸éªŒè¯
    â†“
å®Œæˆï¼
```

### è¯¦ç»†æ­¥éª¤

#### æ­¥éª¤ 1: æå–è§†é¢‘å¸§

```bash
# ä½¿ç”¨ ffmpeg æå–å¸§
ffmpeg -i video.mp4 -q:v 2 frame_%04d.jpg

# æˆ–ä½¿ç”¨ Python
python << 'EOF'
import cv2
import os

video_path = "video.mp4"
output_dir = "frames"
os.makedirs(output_dir, exist_ok=True)

cap = cv2.VideoCapture(video_path)
idx = 0
while True:
    ret, frame = cap.read()
    if not ret:
        break
    cv2.imwrite(f"{output_dir}/frame_{idx:04d}.jpg", frame)
    idx += 1
cap.release()

print(f"æå–äº† {idx} å¸§")
EOF
```

#### æ­¥éª¤ 2: ç”Ÿæˆæ·±åº¦å›¾ (Depth Anything V2)

```bash
# å®‰è£… Depth Anything V2
pip install -e git+https://github.com/DepthAnything/Depth-Anything-V2.git

# è¿è¡Œæ¨ç†
python << 'EOF'
from depth_anything_v2.dpt import DepthAnythingV2

# åˆå§‹åŒ–æ¨¡å‹
model = DepthAnythingV2(
    encoder='vitb',  # vitb, vitl, vitg
    features=256,
    out_channels=[48, 96, 192, 384]
)
model.eval()

import cv2
import numpy as np
import os

frames_dir = "frames"
depth_dir = "depth"
os.makedirs(depth_dir, exist_ok=True)

for frame_file in sorted(os.listdir(frames_dir)):
    frame_path = os.path.join(frames_dir, frame_file)
    frame = cv2.imread(frame_path)
    
    # æ¨ç†
    with torch.no_grad():
        depth = model.infer_image(frame)
    
    # ä¿å­˜
    frame_idx = frame_file.replace("frame_", "").replace(".jpg", "")
    np.save(f"{depth_dir}/frame_{frame_idx}.npy", depth)

print("æ·±åº¦å›¾ç”Ÿæˆå®Œæˆ")
EOF
```

#### æ­¥éª¤ 3: ä¼°è®¡ç‚¹äº‘ (DUSt3R)

```bash
# å®‰è£… DUSt3R
pip install -e git+https://github.com/naver/dust3r.git

# è¿è¡Œæ¨ç†
python << 'EOF'
import torch
from dust3r.model import AsymmetricCroCo3DStereo
from dust3r.inference import inference
import cv2
import numpy as np
import os

# åˆå§‹åŒ–æ¨¡å‹
model = AsymmetricCroCo3DStereo.from_pretrained(
    "naver/DUSt3R_ViTLarge_BaseDecoder_224_linear"
).eval()

frames_dir = "frames"
points_dir = "points"
os.makedirs(points_dir, exist_ok=True)

frame_files = sorted(os.listdir(frames_dir))

# å¤„ç†æ‰€æœ‰å¸§å¯¹ (æˆ–ä»…é‚»è¿‘å¸§å¯¹ä»¥åŠ å¿«é€Ÿåº¦)
for i in range(0, len(frame_files) - 1):
    frame1_path = os.path.join(frames_dir, frame_files[i])
    frame2_path = os.path.join(frames_dir, frame_files[i + 1])
    
    img1 = cv2.imread(frame1_path)
    img2 = cv2.imread(frame2_path)
    
    # DUSt3R æ¨ç†
    with torch.no_grad():
        output = inference([img1, img2], model, device='cuda')
    
    # æå–ç‚¹äº‘ (ä¸‰è§’åŒ–æˆ–å…¶ä»–æ–¹æ³•)
    points1 = extract_points(output['view1'])
    points2 = extract_points(output['view2'])
    
    # ä¿å­˜
    np.save(f"{points_dir}/frame_{i:04d}.npy", points1)
    np.save(f"{points_dir}/frame_{i+1:04d}.npy", points2)

print("ç‚¹äº‘ä¼°è®¡å®Œæˆ")
EOF
```

#### æ­¥éª¤ 4: ä¼°è®¡ç›¸æœºå‚æ•°

**é€‰é¡¹ A: ä½¿ç”¨ COLMAP** (æ¨èç²¾åº¦)

```bash
# å®‰è£… COLMAP
sudo apt-get install colmap

# è¿è¡Œ COLMAP
colmap feature_extractor \
    --database_path database.db \
    --image_path frames/

colmap exhaustive_matcher \
    --database_path database.db

colmap mapper \
    --database_path database.db \
    --image_path frames/ \
    --output_path colmap_output

# å¯¼å‡ºç›¸æœºå‚æ•°
python << 'EOF'
# ä» COLMAP output æå–ç›¸æœºå‚æ•°
# è¯¦è§ COLMAP æ–‡æ¡£æˆ– Fantasy World ç¤ºä¾‹ä»£ç 
EOF
```

**é€‰é¡¹ B: ä½¿ç”¨ DUSt3R è¾“å‡º** (æ›´å¿«)

```python
# DUSt3R çš„è¾“å‡ºä¸­å·²åŒ…å«ç›¸æœºå‚æ•°
# ç›´æ¥ä» DUSt3R çš„ camera matrics æå–
def extract_cameras_from_dust3r(dust3r_output):
    cameras = []
    for view in dust3r_output['views']:
        # æå–å†…å‚å’Œå¤–å‚
        K = view['K']  # 3Ã—3 å†…å‚çŸ©é˜µ
        w2c = view['w2c']  # 3Ã—4 å¤–å‚çŸ©é˜µ
        
        camera = {
            'fx': K[0, 0],
            'fy': K[1, 1],
            'cx': K[0, 2],
            'cy': K[1, 2],
            'k1': 0.0,
            'k2': 0.0,
            'w2c': w2c
        }
        cameras.append(camera)
    return cameras
```

#### æ­¥éª¤ 5: æ•°æ®ç»„ç»‡

```bash
# åˆ›å»ºæœ€ç»ˆçš„æ•°æ®é›†ç»“æ„
mkdir -p dataset/sample_001/{depth,points}

# å¤åˆ¶æ–‡ä»¶
cp video.mp4 dataset/sample_001/
cp -r depth/* dataset/sample_001/depth/
cp -r points/* dataset/sample_001/points/
cp camera_params.txt dataset/sample_001/

# éªŒè¯
find dataset/sample_001/ -type f | sort
```

---

## ğŸ“ æ•°æ®é›†ç»„ç»‡ç»“æ„

### å®Œæ•´ç»“æ„

```
fantasy_world_dataset/
â”‚
â”œâ”€â”€ metadata.json                 # æ•°æ®é›†å…ƒæ•°æ® (å¿…éœ€)
â”‚
â”œâ”€â”€ sample_001/
â”‚   â”œâ”€â”€ video.mp4                # åŸå§‹è§†é¢‘
â”‚   â”œâ”€â”€ depth/
â”‚   â”‚   â”œâ”€â”€ frame_0000.npy
â”‚   â”‚   â”œâ”€â”€ frame_0001.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ points/
â”‚   â”‚   â”œâ”€â”€ frame_0000.npy
â”‚   â”‚   â”œâ”€â”€ frame_0001.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ camera_params.txt        # 19-value ç›¸æœºè½¨è¿¹
â”‚
â”œâ”€â”€ sample_002/
â”‚   â”œâ”€â”€ video.mp4
â”‚   â”œâ”€â”€ depth/
â”‚   â”œâ”€â”€ points/
â”‚   â””â”€â”€ camera_params.txt
â”‚
â””â”€â”€ sample_N/
    â”œâ”€â”€ ...
```

### å…³é”®è¦ç‚¹

1. **metadata.json** ä½ç½®: æ•°æ®é›†æ ¹ç›®å½•
2. **è§†é¢‘æ–‡ä»¶å**: å¿…é¡»æ˜¯ `video.mp4` (æˆ–æŒ‡å®šæ‰©å±•å)
3. **æ·±åº¦æ–‡ä»¶å‘½å**: `frame_0000.npy` æ ¼å¼ï¼Œä» 0 å¼€å§‹ç¼–å·
4. **ç‚¹äº‘æ–‡ä»¶å‘½å**: åŒæ·±åº¦æ–‡ä»¶
5. **ç›¸æœºæ–‡ä»¶å**: å¿…é¡»æ˜¯ `camera_params.txt`

---

## ğŸ“ å…ƒæ•°æ®é…ç½®

### metadata.json æ ¼å¼

```json
{
    "version": "1.0",
    "description": "Fantasy World Training Dataset",
    "samples": [
        {
            "id": "sample_001",
            "video_path": "sample_001/video.mp4",
            "depth_dir": "sample_001/depth",
            "points_dir": "sample_001/points",
            "camera_file": "sample_001/camera_params.txt",
            "num_frames": 81,
            "height": 336,
            "width": 592,
            "fps": 24,
            "scene_type": "indoor",
            "camera_motion": "orbit",
            "note": "Living room with camera rotation"
        },
        {
            "id": "sample_002",
            "video_path": "sample_002/video.mp4",
            "depth_dir": "sample_002/depth",
            "points_dir": "sample_002/points",
            "camera_file": "sample_002/camera_params.txt",
            "num_frames": 81,
            "height": 336,
            "width": 592,
            "fps": 24,
            "scene_type": "outdoor",
            "camera_motion": "forward",
            "note": "Park with camera forward movement"
        }
    ],
    "splits": {
        "train": ["sample_001", "sample_002", ...],
        "val": ["sample_100", "sample_101", ...],
        "test": ["sample_200", "sample_201", ...]
    },
    "statistics": {
        "total_samples": 1000,
        "train_count": 800,
        "val_count": 100,
        "test_count": 100,
        "total_frames": 81000,
        "avg_resolution": "336x592"
    }
}
```

### ç”Ÿæˆ metadata.json

```python
import json
import os
from pathlib import Path

def create_metadata(dataset_dir, output_file):
    """è‡ªåŠ¨ç”Ÿæˆ metadata.json"""
    
    samples = []
    sample_dirs = sorted([d for d in os.listdir(dataset_dir) 
                         if os.path.isdir(os.path.join(dataset_dir, d))])
    
    for sample_id in sample_dirs:
        sample_path = os.path.join(dataset_dir, sample_id)
        
        # æ£€æŸ¥å¿…éœ€æ–‡ä»¶
        video_file = os.path.join(sample_path, "video.mp4")
        depth_dir = os.path.join(sample_path, "depth")
        points_dir = os.path.join(sample_path, "points")
        camera_file = os.path.join(sample_path, "camera_params.txt")
        
        if not all(os.path.exists(p) for p in [video_file, depth_dir, points_dir, camera_file]):
            print(f"âš ï¸ {sample_id} ç¼ºå°‘å¿…éœ€æ–‡ä»¶ï¼Œè·³è¿‡")
            continue
        
        # è·å–å¸§æ•°
        num_frames = len([f for f in os.listdir(depth_dir) if f.endswith('.npy')])
        
        # è·å–åˆ†è¾¨ç‡ (ä»ç¬¬ä¸€å¸§æ·±åº¦å›¾)
        import cv2
        import numpy as np
        first_depth = np.load(os.path.join(depth_dir, "frame_0000.npy"))
        height, width = first_depth.shape
        
        sample = {
            "id": sample_id,
            "video_path": f"{sample_id}/video.mp4",
            "depth_dir": f"{sample_id}/depth",
            "points_dir": f"{sample_id}/points",
            "camera_file": f"{sample_id}/camera_params.txt",
            "num_frames": num_frames,
            "height": int(height),
            "width": int(width),
            "fps": 24,  # å¯æ ¹æ®éœ€è¦è°ƒæ•´
            "scene_type": "unknown",
            "camera_motion": "unknown",
            "note": ""
        }
        samples.append(sample)
    
    # åˆ†å‰²æ•°æ®é›†
    total = len(samples)
    train_count = int(total * 0.8)
    val_count = int(total * 0.1)
    
    train_samples = [s["id"] for s in samples[:train_count]]
    val_samples = [s["id"] for s in samples[train_count:train_count+val_count]]
    test_samples = [s["id"] for s in samples[train_count+val_count:]]
    
    metadata = {
        "version": "1.0",
        "description": "Fantasy World Training Dataset",
        "samples": samples,
        "splits": {
            "train": train_samples,
            "val": val_samples,
            "test": test_samples
        },
        "statistics": {
            "total_samples": total,
            "train_count": len(train_samples),
            "val_count": len(val_samples),
            "test_count": len(test_samples),
            "total_frames": total * num_frames,
            "avg_resolution": f"{height}x{width}"
        }
    }
    
    # ä¿å­˜
    with open(output_file, 'w') as f:
        json.dump(metadata, f, indent=2)
    
    print(f"âœ… metadata.json ç”Ÿæˆå®Œæˆ: {output_file}")
    print(f"   æ€»æ ·æœ¬æ•°: {total}")
    print(f"   è®­ç»ƒ: {len(train_samples)}, éªŒè¯: {len(val_samples)}, æµ‹è¯•: {len(test_samples)}")

# ä½¿ç”¨ç¤ºä¾‹
create_metadata("fantasy_world_dataset", "fantasy_world_dataset/metadata.json")
```

---

## âœ… æ•°æ®éªŒè¯ä¸è´¨é‡æ£€æŸ¥

### éªŒè¯è„šæœ¬

```python
def validate_dataset(dataset_dir, metadata_file):
    """éªŒè¯æ•°æ®é›†å®Œæ•´æ€§å’Œè´¨é‡"""
    
    import json
    import numpy as np
    from pathlib import Path
    
    with open(metadata_file, 'r') as f:
        metadata = json.load(f)
    
    issues = []
    
    for sample in metadata['samples']:
        sample_id = sample['id']
        sample_dir = os.path.join(dataset_dir, sample_id)
        
        # 1. æ£€æŸ¥è§†é¢‘æ–‡ä»¶
        video_file = os.path.join(sample_dir, sample['video_path'])
        if not os.path.exists(video_file):
            issues.append(f"âŒ {sample_id}: è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        
        # 2. æ£€æŸ¥æ·±åº¦å›¾
        depth_dir = os.path.join(sample_dir, sample['depth_dir'])
        depth_files = sorted([f for f in os.listdir(depth_dir) if f.endswith('.npy')])
        if len(depth_files) != sample['num_frames']:
            issues.append(f"âš ï¸ {sample_id}: æ·±åº¦å›¾æ•°é‡ä¸åŒ¹é… ({len(depth_files)} vs {sample['num_frames']})")
        
        # æ£€æŸ¥æ·±åº¦å›¾å€¼åŸŸ
        first_depth = np.load(os.path.join(depth_dir, depth_files[0]))
        if first_depth.max() > 1.1:  # å‡è®¾åº”è¯¥å½’ä¸€åŒ–åˆ° 0-1
            issues.append(f"âš ï¸ {sample_id}: æ·±åº¦å›¾å€¼åŸŸå¼‚å¸¸ (max={first_depth.max()}, åº”è¯¥ â‰¤ 1)")
        
        # 3. æ£€æŸ¥ç‚¹äº‘
        points_dir = os.path.join(sample_dir, sample['points_dir'])
        points_files = sorted([f for f in os.listdir(points_dir) if f.endswith('.npy')])
        if len(points_files) != sample['num_frames']:
            issues.append(f"âš ï¸ {sample_id}: ç‚¹äº‘æ•°é‡ä¸åŒ¹é…")
        
        # æ£€æŸ¥ç‚¹äº‘ç»´åº¦
        first_points = np.load(os.path.join(points_dir, points_files[0]))
        if first_points.shape != (sample['height'], sample['width'], 3):
            issues.append(f"âš ï¸ {sample_id}: ç‚¹äº‘ç»´åº¦ä¸åŒ¹é… ({first_points.shape})")
        
        # 4. æ£€æŸ¥ç›¸æœºæ–‡ä»¶
        camera_file = os.path.join(sample_dir, sample['camera_file'])
        if not os.path.exists(camera_file):
            issues.append(f"âŒ {sample_id}: ç›¸æœºæ–‡ä»¶ä¸å­˜åœ¨")
        else:
            with open(camera_file, 'r') as f:
                camera_lines = f.readlines()
            if len(camera_lines) != sample['num_frames']:
                issues.append(f"âš ï¸ {sample_id}: ç›¸æœºå‚æ•°è¡Œæ•°ä¸åŒ¹é… ({len(camera_lines)} vs {sample['num_frames']})")
    
    # è¾“å‡ºç»“æœ
    if issues:
        print("ğŸ” éªŒè¯ç»“æœ:")
        for issue in issues:
            print(f"  {issue}")
        return False
    else:
        print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼æ•°æ®é›†æœ‰æ•ˆ")
        return True

# ä½¿ç”¨
validate_dataset("fantasy_world_dataset", "fantasy_world_dataset/metadata.json")
```

### è´¨é‡æ£€æŸ¥æ¸…å•

```
æ•°æ®é›†å®Œæ•´æ€§æ£€æŸ¥:
âœ… metadata.json å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
âœ… æ‰€æœ‰æ ·æœ¬ç›®å½•å­˜åœ¨
âœ… æ¯ä¸ªæ ·æœ¬éƒ½æœ‰ video.mp4
âœ… æ·±åº¦å›¾æ•°é‡ä¸å¸§æ•°åŒ¹é…
âœ… ç‚¹äº‘æ•°é‡ä¸å¸§æ•°åŒ¹é…
âœ… ç›¸æœºæ–‡ä»¶è¡Œæ•°ä¸å¸§æ•°åŒ¹é…

æ•°æ®è´¨é‡æ£€æŸ¥:
âœ… è§†é¢‘æ— æŸåæˆ–é»‘å¸§
âœ… æ·±åº¦å›¾å€¼åœ¨åˆç†èŒƒå›´ (0-1 æˆ– 0-255)
âœ… ç‚¹äº‘ä¸æ˜¯å…¨ NaN æˆ–æ— ç©·å¤§
âœ… ç›¸æœºå‚æ•°åœ¨åˆç†èŒƒå›´
âœ… æ·±åº¦å›¾å’Œç‚¹äº‘çš„åˆ†è¾¨ç‡åŒ¹é…

ç»Ÿè®¡æ£€æŸ¥:
âœ… è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†æ•°é‡åˆç†
âœ… æ•°æ®é›†å¤§å°è¶³å¤Ÿ (â‰¥ 100 ä¸ªæ ·æœ¬)
âœ… æ— é‡å¤æ ·æœ¬
```

---

## ğŸ› å¸¸è§æ•°æ®é—®é¢˜è§£å†³

### é—®é¢˜ 1: æ·±åº¦å›¾å€¼åŸŸä¸å¯¹

**ç—‡çŠ¶**: è®­ç»ƒæ—¶æ·±åº¦ loss å¼‚å¸¸å¤§

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥å¹¶ä¿®å¤
def fix_depth_values(depth_dir):
    import numpy as np
    import os
    
    for file in os.listdir(depth_dir):
        if not file.endswith('.npy'):
            continue
        
        depth = np.load(os.path.join(depth_dir, file))
        
        # å¦‚æœæœ€å¤§å€¼ > 1.5ï¼Œè¿›è¡Œå½’ä¸€åŒ–
        if depth.max() > 1.5:
            depth = depth / 255.0  # å‡è®¾åŸå§‹å€¼ 0-255
            np.save(os.path.join(depth_dir, file), depth)
            print(f"å·²ä¿®å¤: {file}")
```

### é—®é¢˜ 2: ç‚¹äº‘åŒ…å« NaN

**ç—‡çŠ¶**: è®­ç»ƒå´©æºƒæˆ–æ¢¯åº¦ä¸º NaN

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥å’Œæ¸…ç†
def clean_points(points_dir):
    import numpy as np
    import os
    
    for file in os.listdir(points_dir):
        if not file.endswith('.npy'):
            continue
        
        points = np.load(os.path.join(points_dir, file))
        
        # æ›¿æ¢ NaN ä¸º 0
        if np.isnan(points).any():
            print(f"âš ï¸ {file} åŒ…å« NaNï¼Œæ­£åœ¨ä¿®å¤...")
            points = np.nan_to_num(points, nan=0.0)
            np.save(os.path.join(points_dir, file), points)
```

### é—®é¢˜ 3: ç›¸æœºæ–‡ä»¶æ ¼å¼é”™è¯¯

**ç—‡çŠ¶**: "æ— æ³•è§£æç›¸æœºæ–‡ä»¶" é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥å’Œä¿®å¤æ ¼å¼
def verify_camera_format(camera_file):
    with open(camera_file, 'r') as f:
        for line_idx, line in enumerate(f):
            values = line.strip().split()
            
            # æ£€æŸ¥å€¼æ•°é‡ (åº”è¯¥æ˜¯ 19)
            if len(values) != 19:
                print(f"âŒ ç¬¬ {line_idx} è¡Œ: å€¼æ•°é‡ {len(values)} != 19")
                return False
            
            # å°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
            try:
                values = [float(v) for v in values]
            except ValueError as e:
                print(f"âŒ ç¬¬ {line_idx} è¡Œ: æ— æ³•è½¬æ¢ä¸ºæ•°å­— - {e}")
                return False
    
    print("âœ… ç›¸æœºæ–‡ä»¶æ ¼å¼æ­£ç¡®")
    return True

# ä½¿ç”¨
verify_camera_format("sample_001/camera_params.txt")
```

### é—®é¢˜ 4: åˆ†è¾¨ç‡ä¸ä¸€è‡´

**ç—‡çŠ¶**: "ç»´åº¦ä¸åŒ¹é…" é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```python
# é‡æ–°è°ƒæ•´æ‰€æœ‰æ•°æ®åˆ°ç»Ÿä¸€åˆ†è¾¨ç‡
def resize_all_data(sample_dir, target_height=336, target_width=592):
    import cv2
    import numpy as np
    import os
    from PIL import Image
    
    # è°ƒæ•´è§†é¢‘ (ä½¿ç”¨ ffmpeg)
    import subprocess
    video_file = os.path.join(sample_dir, "video.mp4")
    subprocess.run([
        'ffmpeg', '-i', video_file,
        '-vf', f'scale={target_width}:{target_height}',
        '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
        os.path.join(sample_dir, "video_resized.mp4")
    ])
    
    # è°ƒæ•´æ·±åº¦å›¾
    depth_dir = os.path.join(sample_dir, "depth")
    for file in os.listdir(depth_dir):
        if not file.endswith('.npy'):
            continue
        
        depth = np.load(os.path.join(depth_dir, file))
        depth_resized = cv2.resize(depth, (target_width, target_height))
        np.save(os.path.join(depth_dir, file), depth_resized)
    
    # ç±»ä¼¼åœ°å¤„ç†ç‚¹äº‘
    points_dir = os.path.join(sample_dir, "points")
    for file in os.listdir(points_dir):
        if not file.endswith('.npy'):
            continue
        
        points = np.load(os.path.join(points_dir, file))
        # è°ƒæ•´ç©ºé—´ç»´åº¦ï¼Œä¿æŒ 3 é€šé“
        points_resized = cv2.resize(
            points,
            (target_width, target_height),
            interpolation=cv2.INTER_LINEAR
        )
        np.save(os.path.join(points_dir, file), points_resized)
    
    print("âœ… æ‰€æœ‰æ•°æ®å·²è°ƒæ•´åˆ°ç»Ÿä¸€åˆ†è¾¨ç‡")
```

---

**ä¸‹ä¸€æ­¥**: æŸ¥çœ‹ [è®­ç»ƒæŒ‡å—](./TRAINING_GUIDE.md) å¼€å§‹è®­ç»ƒï¼
