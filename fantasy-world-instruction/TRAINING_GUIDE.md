# ğŸ“ è¯¦ç»†è®­ç»ƒæŒ‡å— - ä¸¤é˜¶æ®µå®Œæ•´ç‰ˆ

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜ Fantasy World çš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ã€é…ç½®ã€ç›‘æ§å’Œä¼˜åŒ–æ–¹æ³•ã€‚

---

## ğŸ“‹ ç›®å½•

1. [ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥](#ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥)
2. [ç¯å¢ƒä¸å‡†å¤‡](#ç¯å¢ƒä¸å‡†å¤‡)
3. [Stage 1: Latent Bridging](#stage-1-latent-bridging)
4. [Stage 2: Unified Co-Optimization](#stage-2-unified-co-optimization)
5. [è®­ç»ƒç›‘æ§ä¸è°ƒè¯•](#è®­ç»ƒç›‘æ§ä¸è°ƒè¯•)
6. [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
7. [æ•…éšœæ¢å¤ä¸æ£€æŸ¥ç‚¹ç®¡ç†](#æ•…éšœæ¢å¤ä¸æ£€æŸ¥ç‚¹ç®¡ç†)

---

## ğŸ”„ ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥

### ä¸ºä»€ä¹ˆéœ€è¦ä¸¤é˜¶æ®µï¼Ÿ

**é—®é¢˜**: ç›´æ¥è”åˆè®­ç»ƒæ‰€æœ‰æ¨¡å—å¯¼è‡´ï¼š
- âŒ Geometry branch æ— æ³•æœ‰æ•ˆå­¦ä¹  (video features ä¸ç¨³å®š)
- âŒ æ¢¯åº¦å†²çª (ä¸åŒåˆ†æ”¯å­¦ä¹ ç›®æ ‡ä¸ä¸€è‡´)
- âŒ è®­ç»ƒä¸ç¨³å®š (loss éœ‡è¡ï¼Œæ”¶æ•›å›°éš¾)
- âŒ æ¨¡å‹æ€§èƒ½å·® (æœ€ç»ˆè¾“å‡ºä¸ç†æƒ³)

**è§£å†³æ–¹æ¡ˆ**: ä¸¤é˜¶æ®µç­–ç•¥

```
Stage 1 (ç¨³å®šé€‚é…)              Stage 2 (åŒå‘äº¤äº’)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
å†»ç»“è§†é¢‘åˆ†æ”¯                    ç»§ç»­å†»ç»“è§†é¢‘åˆ†æ”¯
    â†“                                â†“
è®©å‡ ä½•åˆ†æ”¯é€‚é…                   æ·»åŠ äº¤äº’æ¨¡å—
    â†“                                â†“
å‡ ä½• loss å¿«é€Ÿä¸‹é™              æ•´ä½“ loss å¾®è°ƒä¼˜åŒ–
    â†“                                â†“
æ”¶æ•›åˆ°å±€éƒ¨æœ€ä¼˜                   æ‰¾åˆ°å…¨å±€æ›´ä¼˜è§£
```

### è®ºæ–‡è®¾è®¡ vs æˆ‘ä»¬çš„å®ç°

| æ–¹é¢ | è®ºæ–‡è®¾è®¡ | æˆ‘ä»¬çš„å®ç° |
|------|---------|---------|
| **æ€» DiT å±‚æ•°** | 40 | 30 |
| **PCB å±‚æ•°** | ä¸æ˜ç¡® | 12 |
| **IRG å±‚æ•°** | ä¸æ˜ç¡® | 18 |
| **Stage 1 æ­¥æ•°** | 20,000 | 20,000 âœ… |
| **Stage 2 æ­¥æ•°** | 10,000 | 10,000 âœ… |
| **Stage 1 batch** | 64 | 64 âœ… |
| **Stage 2 batch** | 112 | 112 âœ… |

---

## ğŸ”§ ç¯å¢ƒä¸å‡†å¤‡

### å‰ç½®è¦æ±‚

**ç¡¬ä»¶**:
- 8 Ã— NVIDIA H20 æˆ– A100 (40GB æ˜¾å­˜)
- 500GB+ ç¡¬ç›˜ç©ºé—´ (ç”¨äºæ£€æŸ¥ç‚¹å’Œä¸´æ—¶æ–‡ä»¶)
- ç½‘ç»œè¿æ¥ (ä¸‹è½½æ¨¡å‹æƒé‡)

**è½¯ä»¶**:
- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (ä»… NVIDIA)
- DiffSynth-Studio (å·²å®‰è£…)

### ç¯å¢ƒæ£€æŸ¥

```bash
# 1. æ£€æŸ¥ Python ç‰ˆæœ¬
python --version

# 2. æ£€æŸ¥ PyTorch
python -c "import torch; print(torch.__version__)"

# 3. æ£€æŸ¥ CUDA
python -c "import torch; print(torch.cuda.is_available())"

# 4. æ£€æŸ¥ GPU
python -c "import torch; print(torch.cuda.get_device_name(0))"

# 5. æ£€æŸ¥æ˜¾å­˜
python -c "import torch; print(f'{torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB')"
```

**é¢„æœŸè¾“å‡º**:
```
Python 3.9.18
2.0.1+cu118
True
NVIDIA H20 Tensor Core GPU
40.0 GB
```

### é¡¹ç›®å®‰è£…

```bash
cd /ML-vePFS/research_gen/jmy/jmy_ws/Diffsynth-fantasy-world

# å¼€å‘æ¨¡å¼å®‰è£… (å¯ç¼–è¾‘)
pip install -e .

# éªŒè¯
python -c "import diffsynth; print('âœ… å®‰è£…æˆåŠŸ')"
```

### æ•°æ®å‡†å¤‡

ç¡®ä¿æ•°æ®é›†ç»“æ„æ­£ç¡®:

```
fantasy_world_dataset/
â”œâ”€â”€ metadata.json
â”œâ”€â”€ sample_001/
â”‚   â”œâ”€â”€ video.mp4
â”‚   â”œâ”€â”€ depth/
â”‚   â”œâ”€â”€ points/
â”‚   â””â”€â”€ camera_params.txt
â”œâ”€â”€ sample_002/
â””â”€â”€ ...
```

è¯¦è§ [æ•°æ®å‡†å¤‡æŒ‡å—](./DATA_PREPARATION.md)

---

## ğŸŸ¢ Stage 1: Latent Bridging

### ç›®æ ‡ä¸åŸç†

**ç›®æ ‡**: è®­ç»ƒå‡ ä½•åˆ†æ”¯ä»¥é€‚é…åˆ°å†»ç»“çš„è§†é¢‘ç‰¹å¾ç©ºé—´

**å¯è®­ç»ƒæ¨¡å—**:
- âœ… Latent Bridge Adapter (~5M å‚æ•°)
- âœ… GeoDiT Blocks (18 layers, ~900M å‚æ•°)
- âœ… DPT Heads (Depth, Point, Camera, ~50M å‚æ•°)
- âœ… Pose Encoder (~1M å‚æ•°)
- âœ… Special Tokens (Camera + Register, ~0.01M å‚æ•°)

**å†»ç»“æ¨¡å—**:
- â„ï¸ Wan2.1 æ‰€æœ‰ 30 blocks (~1616M å‚æ•°)
- â„ï¸ Camera Adapters (~30M å‚æ•°)
- â„ï¸ IRG Cross-Attention (~200M å‚æ•°)

**æ€»å¯è®­ç»ƒå‚æ•°**: ~956M

### é…ç½®æ–‡ä»¶

ç¼–è¾‘ `examples/wanvideo/model_training/full/train_fantasy_world_stage1.sh`:

```bash
#!/bin/bash

# ====== æ•°æ®é…ç½® ======
DATA_DIR="/path/to/fantasy_world_dataset"           # ä¿®æ”¹è¿™é‡Œï¼
DATASET_METADATA="$DATA_DIR/metadata.json"

# ====== è¾“å‡ºé…ç½® ======
OUTPUT_DIR="./outputs/fantasy_world_stage1"
mkdir -p "$OUTPUT_DIR"

# ====== GPU é…ç½® ======
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7              # ä½¿ç”¨ 8 å— GPU
NUM_GPUS=8

# ====== è®­ç»ƒå‚æ•° ======
NUM_STEPS=20000
BATCH_SIZE_PER_GPU=8                               # 8 Ã— 8 = 64 å…¨å±€ batch
LEARNING_RATE=1e-5
GRADIENT_ACCUMULATION=1                            # æ¢¯åº¦ç´¯ç§¯æ­¥æ•° (å¯é€‰)

# ====== æ•°æ®å‚æ•° ======
HEIGHT=336
WIDTH=592
NUM_FRAMES=21                                       # Stage 1 ä½¿ç”¨è¾ƒå°‘å¸§

# ====== æ¨¡å‹å‚æ•° ======
TASK="fantasy_world:stage1"                        # å…³é”®ï¼šæŒ‡å®š stage1
TRAINABLE_MODELS="dit"                             # è®­ç»ƒ DiT æ¨¡å—

# ====== å…¶ä»–å‚æ•° ======
MIXED_PRECISION="bf16"                             # BFloat16 æ··åˆç²¾åº¦
FIND_UNUSED_PARAMS="--find_unused_parameters"      # å¤„ç†å†»ç»“å‚æ•° (DDP)

# ====== è¿è¡Œè®­ç»ƒ ======
python -m torch.distributed.launch \
    --nproc_per_node=$NUM_GPUS \
    examples/wanvideo/model_training/train.py \
    --task $TASK \
    --dataset_base_path "$DATA_DIR" \
    --dataset_metadata_path "$DATASET_METADATA" \
    --output_path "$OUTPUT_DIR" \
    --num_steps $NUM_STEPS \
    --batch_size_per_gpu $BATCH_SIZE_PER_GPU \
    --learning_rate $LEARNING_RATE \
    --gradient_accumulation $GRADIENT_ACCUMULATION \
    --height $HEIGHT \
    --width $WIDTH \
    --num_frames $NUM_FRAMES \
    --mixed_precision $MIXED_PRECISION \
    --trainable_models $TRAINABLE_MODELS \
    $FIND_UNUSED_PARAMS
```

### å…³é”®é…ç½®è¯´æ˜

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `DATA_DIR` | `/path/to/dataset` | **å¿…æ”¹**: ä½ çš„æ•°æ®é›†è·¯å¾„ |
| `TASK` | `fantasy_world:stage1` | **å¿…é¡»**: æŒ‡å®š stage1 |
| `NUM_STEPS` | 20000 | è®ºæ–‡æ¨èå€¼ |
| `BATCH_SIZE_PER_GPU` | 8 | 8 GPUs â†’ å…¨å±€ batch 64 |
| `HEIGHT` Ã— `WIDTH` | 336 Ã— 592 | Stage 1 åˆ†è¾¨ç‡ |
| `NUM_FRAMES` | 21 | Stage 1 å¸§æ•° |
| `LEARNING_RATE` | 1e-5 | æ ‡å‡†å­¦ä¹ ç‡ |
| `MIXED_PRECISION` | bf16 | BFloat16 èŠ‚çœæ˜¾å­˜ |
| `--find_unused_parameters` | å¯ç”¨ | å¤„ç† DDP å†»ç»“å‚æ•°é—®é¢˜ |

### è¿è¡Œ Stage 1

```bash
# 1. ç¼–è¾‘é…ç½®
vim examples/wanvideo/model_training/full/train_fantasy_world_stage1.sh
# ä¿®æ”¹ DATA_DIR ä¸ºä½ çš„æ•°æ®é›†è·¯å¾„

# 2. èµ‹äºˆæ‰§è¡Œæƒé™
chmod +x examples/wanvideo/model_training/full/train_fantasy_world_stage1.sh

# 3. è¿è¡Œè®­ç»ƒ
cd /ML-vePFS/research_gen/jmy/jmy_ws/Diffsynth-fantasy-world
bash examples/wanvideo/model_training/full/train_fantasy_world_stage1.sh
```

### æ€§èƒ½æœŸæœ›

**è®­ç»ƒæ—¶é—´**:
- ç¡¬ä»¶: 8 Ã— H20
- 20K steps: ~36 å°æ—¶

**Loss æœŸæœ›å€¼**:
```
Step 1000:
  - L_diffusion: 0.5-0.8
  - L_depth: 0.3-0.5
  - L_point: 1.0-1.5
  - L_camera: 0.2-0.3
  
Step 10000 (ä¸­æœŸ):
  - L_diffusion: 0.2-0.3
  - L_depth: 0.1-0.15
  - L_point: 0.4-0.6
  - L_camera: 0.05-0.1
  
Step 20000 (å®Œæˆ):
  - L_diffusion: 0.15-0.25
  - L_depth: < 0.1
  - L_point: 0.2-0.4
  - L_camera: < 0.05
```

**æ£€æŸ¥ç‚¹è¾“å‡º**:

```
outputs/fantasy_world_stage1/
â”œâ”€â”€ step-1000.safetensors
â”œâ”€â”€ step-2000.safetensors
â”œâ”€â”€ ...
â””â”€â”€ step-20000.safetensors  # æœ€ç»ˆ Stage 1 æ£€æŸ¥ç‚¹ â­
```

### è´¨é‡è¯„ä¼°

Stage 1 å®Œæˆåï¼ŒéªŒè¯è®­ç»ƒè´¨é‡:

```python
# åŠ è½½æ£€æŸ¥ç‚¹å¹¶æµ‹è¯•æ¨ç†
import torch
from diffsynth import WanVideoPipeline

checkpoint = "outputs/fantasy_world_stage1/step-20000.safetensors"

pipe = WanVideoPipeline.from_pretrained("PAI/Wan2.1-Fun-V1.1-1.3B")
pipe.dit.enable_fantasy_world_mode(training_stage="stage1")
state = torch.load(checkpoint, map_location="cpu")
pipe.dit.load_state_dict(state, strict=False)

# æµ‹è¯•æ¨ç†
video = pipe(
    prompt="a camera moving through a room",
    num_frames=21,
    height=336,
    width=592
)

print("âœ… Stage 1 æ¨ç†æˆåŠŸ")
```

---

## ğŸ”µ Stage 2: Unified Co-Optimization

### ç›®æ ‡ä¸åŸç†

**ç›®æ ‡**: æ·»åŠ äº¤äº’æ¨¡å—ï¼Œå®ç°è§†é¢‘-å‡ ä½•çš„åŒå‘äº¤äº’

**æ–°å¢å¯è®­ç»ƒæ¨¡å—**:
- âœ… Camera Adapters (12 ä¸ª, ~30M å‚æ•°)
- âœ… IRG Cross-Attention (18 ä¸ª, ~200M å‚æ•°)

**ç»§ç»­è®­ç»ƒ**:
- âœ… ä¿ç•™ Stage 1 çš„æ‰€æœ‰å¯è®­ç»ƒæ¨¡å—

**å†»ç»“æ¨¡å—**:
- â„ï¸ Wan2.1 æ‰€æœ‰ 30 blocks (å§‹ç»ˆå†»ç»“)

**æ€»å¯è®­ç»ƒå‚æ•°**: ~1186M (æ¯” Stage 1 å¤š 230M)

### é…ç½®æ–‡ä»¶

ç¼–è¾‘ `examples/wanvideo/model_training/full/train_fantasy_world_stage2.sh`:

```bash
#!/bin/bash

# ====== æ•°æ®é…ç½® ======
DATA_DIR="/path/to/fantasy_world_dataset"
DATASET_METADATA="$DATA_DIR/metadata.json"

# ====== æ£€æŸ¥ç‚¹é…ç½® ======
STAGE1_CHECKPOINT="outputs/fantasy_world_stage1/step-20000.safetensors"  # å¿…éœ€ï¼

# ====== è¾“å‡ºé…ç½® ======
OUTPUT_DIR="./outputs/fantasy_world_stage2"
mkdir -p "$OUTPUT_DIR"

# ====== GPU é…ç½® ======
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
NUM_GPUS=8

# ====== è®­ç»ƒå‚æ•° ======
NUM_STEPS=10000
BATCH_SIZE_PER_GPU=14                              # 8 Ã— 14 = 112 å…¨å±€ batch
LEARNING_RATE=1e-5
GRADIENT_ACCUMULATION=1

# ====== æ•°æ®å‚æ•° ======
HEIGHT=592
WIDTH=336                                           # æ³¨æ„ï¼šåˆ†è¾¨ç‡ä¸ Stage 1 äº’æ¢
NUM_FRAMES=81                                       # Stage 2 ä½¿ç”¨å®Œæ•´å¸§æ•°

# ====== æ¨¡å‹å‚æ•° ======
TASK="fantasy_world:stage2"                        # å…³é”®ï¼šæŒ‡å®š stage2
TRAINABLE_MODELS="dit"

# ====== å…¶ä»–å‚æ•° ======
MIXED_PRECISION="bf16"
FIND_UNUSED_PARAMS="--find_unused_parameters"

# ====== å‰ç½®æ£€æŸ¥ ======
if [ ! -f "$STAGE1_CHECKPOINT" ]; then
    echo "âŒ é”™è¯¯: Stage 1 æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: $STAGE1_CHECKPOINT"
    echo "è¯·å…ˆè¿è¡Œ Stage 1 è®­ç»ƒ"
    exit 1
fi

# ====== è¿è¡Œè®­ç»ƒ ======
python -m torch.distributed.launch \
    --nproc_per_node=$NUM_GPUS \
    examples/wanvideo/model_training/train.py \
    --task $TASK \
    --stage1_checkpoint "$STAGE1_CHECKPOINT" \
    --dataset_base_path "$DATA_DIR" \
    --dataset_metadata_path "$DATASET_METADATA" \
    --output_path "$OUTPUT_DIR" \
    --num_steps $NUM_STEPS \
    --batch_size_per_gpu $BATCH_SIZE_PER_GPU \
    --learning_rate $LEARNING_RATE \
    --gradient_accumulation $GRADIENT_ACCUMULATION \
    --height $HEIGHT \
    --width $WIDTH \
    --num_frames $NUM_FRAMES \
    --mixed_precision $MIXED_PRECISION \
    --trainable_models $TRAINABLE_MODELS \
    $FIND_UNUSED_PARAMS
```

### å…³é”®é…ç½®è¯´æ˜

| å‚æ•° | å€¼ | è¯´æ˜ |
|------|-----|------|
| `STAGE1_CHECKPOINT` | `outputs/fantasy_world_stage1/step-20000.safetensors` | **å¿…éœ€**: Stage 1 è¾“å‡º |
| `TASK` | `fantasy_world:stage2` | **å¿…é¡»**: æŒ‡å®š stage2 |
| `NUM_STEPS` | 10000 | æ¯” Stage 1 å°‘ |
| `BATCH_SIZE_PER_GPU` | 14 | 8 GPUs â†’ å…¨å±€ batch 112 |
| `HEIGHT` Ã— `WIDTH` | 592 Ã— 336 | å®Œæ•´åˆ†è¾¨ç‡ï¼Œä¸ Stage 1 äº’æ¢ |
| `NUM_FRAMES` | 81 | å®Œæ•´è§†é¢‘é•¿åº¦ |
| `LEARNING_RATE` | 1e-5 | ä¿æŒä¸å˜ |

### è¿è¡Œ Stage 2

```bash
# 1. éªŒè¯ Stage 1 å®Œæˆ
ls -lh outputs/fantasy_world_stage1/step-20000.safetensors

# 2. ç¼–è¾‘ Stage 2 é…ç½®
vim examples/wanvideo/model_training/full/train_fantasy_world_stage2.sh

# 3. èµ‹äºˆæ‰§è¡Œæƒé™
chmod +x examples/wanvideo/model_training/full/train_fantasy_world_stage2.sh

# 4. è¿è¡Œ Stage 2
bash examples/wanvideo/model_training/full/train_fantasy_world_stage2.sh
```

### æ€§èƒ½æœŸæœ›

**è®­ç»ƒæ—¶é—´**:
- ç¡¬ä»¶: 8 Ã— H20
- 10K steps: ~144 å°æ—¶

**Loss æœŸæœ›å€¼**:
```
Step 1000 (ä» Stage 1 checkpoint åˆå§‹åŒ–):
  - L_diffusion: 0.2-0.3        # æ›´ä½çš„èµ·ç‚¹
  - L_depth: 0.08-0.12
  - L_point: 0.3-0.5
  - L_camera: 0.05-0.08
  
Step 5000 (ä¸­æœŸ):
  - L_diffusion: 0.12-0.18
  - L_depth: 0.05-0.08
  - L_point: 0.15-0.25
  - L_camera: 0.03-0.05
  
Step 10000 (å®Œæˆ):
  - L_diffusion: 0.1-0.15
  - L_depth: < 0.05
  - L_point: 0.1-0.2
  - L_camera: < 0.03
```

### æœ€ç»ˆæ¨¡å‹

```
outputs/fantasy_world_stage2/
â””â”€â”€ step-10000.safetensors  # æœ€ç»ˆæ¨¡å‹ â­â­â­
```

è¿™ä¸ªæ¨¡å‹åŒ…å«å®Œæ•´çš„ Fantasy World èƒ½åŠ›ï¼Œå¯ç”¨äºæ¨ç†ã€‚

---

## ğŸ“Š è®­ç»ƒç›‘æ§ä¸è°ƒè¯•

### å®æ—¶ç›‘æ§

#### æ–¹æ³• 1: TensorBoard

```bash
# å¯åŠ¨ TensorBoard
tensorboard --logdir outputs/fantasy_world_stage1

# åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€
# http://localhost:6006
```

#### æ–¹æ³• 2: æ—¥å¿—æ–‡ä»¶

```bash
# Stage 1 æ—¥å¿—
tail -f outputs/fantasy_world_stage1/training.log

# æŸ¥çœ‹æœ€å 100 è¡Œ
tail -100 outputs/fantasy_world_stage1/training.log
```

#### æ–¹æ³• 3: è„šæœ¬ç›‘æ§

```python
# monitor_training.py
import json
from pathlib import Path
import time

def monitor_training(log_dir):
    while True:
        log_file = Path(log_dir) / "training.log"
        if log_file.exists():
            lines = log_file.read_text().strip().split('\n')
            if lines:
                last_line = lines[-1]
                print(f"\r{last_line}", end="")
        time.sleep(5)

if __name__ == "__main__":
    monitor_training("outputs/fantasy_world_stage1")
```

### å…³é”®æŒ‡æ ‡

ç›‘æ§è¿™äº›æŒ‡æ ‡åˆ¤æ–­è®­ç»ƒçŠ¶æ€ï¼š

| æŒ‡æ ‡ | å«ä¹‰ | æ­£å¸¸èŒƒå›´ | è­¦å‘Šé˜ˆå€¼ |
|------|------|---------|---------|
| `loss/diffusion` | æ‰©æ•£æŸå¤± | é€æ­¥é€’å‡ | ä¸é™æˆ–æ³¢åŠ¨å¤§ |
| `loss/depth` | æ·±åº¦é¢„æµ‹æŸå¤± | å¿«é€Ÿé€’å‡ | > 0.2 (Stage 1åæœŸ) |
| `loss/point` | ç‚¹äº‘é¢„æµ‹æŸå¤± | é€æ­¥é€’å‡ | > 0.5 (Stage 1åæœŸ) |
| `loss/camera` | ç›¸æœºå‚æ•°æŸå¤± | å¿«é€Ÿé€’å‡ | > 0.1 (Stage 1åæœŸ) |
| `learning_rate` | å­¦ä¹ ç‡ | å›ºå®šæˆ–è¡°å‡ | æ„å¤–å˜åŒ– |
| `gpu_memory` | GPU æ˜¾å­˜ä½¿ç”¨ | ç¨³å®š | æŒç»­å¢é•¿ |

### å¼‚å¸¸æ’æŸ¥

#### é—®é¢˜ 1: Loss ä¸ä¸‹é™æˆ–åå‘å¢é•¿

**ç—‡çŠ¶**:
```
Step 1000: loss = 1.5
Step 2000: loss = 1.7
Step 3000: loss = 2.0
```

**å¯èƒ½åŸå› **:
1. å­¦ä¹ ç‡è¿‡é«˜
2. æ•°æ®ä¸é€‚é…
3. æ¨¡å‹æ¶æ„é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å°è¯•é™ä½å­¦ä¹ ç‡
LEARNING_RATE=5e-6  # åŸæ¥æ˜¯ 1e-5

# æˆ–æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
python scripts/verify_dataset.py --dataset_path $DATA_DIR
```

#### é—®é¢˜ 2: GPU æ˜¾å­˜æº¢å‡º

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# é€‰é¡¹ 1: å‡å° batch size
BATCH_SIZE_PER_GPU=4  # ä» 8 é™ä½

# é€‰é¡¹ 2: å¢åŠ æ¢¯åº¦ç´¯ç§¯
GRADIENT_ACCUMULATION=2  # è¡¥å¿ batch size ä¸‹é™

# é€‰é¡¹ 3: å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ (éœ€è¦ä»£ç ä¿®æ”¹)
```

#### é—®é¢˜ 3: Loss éœ‡è¡æˆ–ä¸æ”¶æ•›

**ç—‡çŠ¶**:
```
Step 5000: loss = 0.15
Step 5100: loss = 0.25
Step 5200: loss = 0.12
...
```

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ä½¿ç”¨åŠ¨æ€å­¦ä¹ ç‡è°ƒåº¦
# åœ¨è®­ç»ƒè„šæœ¬ä¸­é…ç½® lr_scheduler

# æˆ–æ‰‹åŠ¨é™ä½å­¦ä¹ ç‡åç»§ç»­
LEARNING_RATE=5e-6
```

---

## âš™ï¸ æ€§èƒ½ä¼˜åŒ–

### æ˜¾å­˜ä¼˜åŒ–

**æªæ–½**:
1. **æ··åˆç²¾åº¦è®­ç»ƒ** (å·²å¯ç”¨)
   ```bash
   MIXED_PRECISION="bf16"  # BFloat16
   ```

2. **æ¢¯åº¦æ£€æŸ¥ç‚¹** (å¯é€‰)
   ```python
   # åœ¨ train.py ä¸­å¯ç”¨
   model.gradient_checkpointing_enable()
   ```

3. **å‡å° batch size** (æœ€åæ‰‹æ®µ)
   ```bash
   BATCH_SIZE_PER_GPU=4  # é»˜è®¤ 8
   ```

### è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–

**æªæ–½**:
1. **æ•°æ®é¢„åŠ è½½** (é€šå¸¸å·²è‡ªåŠ¨)
2. **å¤š GPU åŒæ­¥é¢‘ç‡**
   ```bash
   # æ¯ N æ­¥åŒæ­¥ä¸€æ¬¡æ¢¯åº¦
   GRADIENT_ACCUMULATION=2
   ```

3. **å…³é—­ä¸å¿…è¦çš„æ£€æŸ¥**
   ```bash
   # å‡å°‘ checkpoint ä¿å­˜é¢‘ç‡
   SAVE_EVERY=500  # ä¸æ˜¯ 100
   ```

### æœ€å¤§ååé‡é…ç½®

ä¸ºäº†æœ€å¤§åŒ–è®­ç»ƒé€Ÿåº¦:

```bash
NUM_STEPS=20000
BATCH_SIZE_PER_GPU=8
GRADIENT_ACCUMULATION=1
MIXED_PRECISION="bf16"
SAVE_EVERY=1000  # ä¸é¢‘ç¹ä¿å­˜

# é¢„æœŸ: 20-30 æ ·æœ¬/ç§’
```

---

## ğŸ”„ æ•…éšœæ¢å¤ä¸æ£€æŸ¥ç‚¹ç®¡ç†

### æ£€æŸ¥ç‚¹ç»“æ„

```
outputs/fantasy_world_stage1/
â”œâ”€â”€ step-1000.safetensors     # ä¸­é—´æ£€æŸ¥ç‚¹
â”œâ”€â”€ step-2000.safetensors
â”œâ”€â”€ ...
â”œâ”€â”€ step-20000.safetensors    # æœ€ç»ˆæ£€æŸ¥ç‚¹ â­
â”œâ”€â”€ latest.safetensors        # æœ€æ–°æ£€æŸ¥ç‚¹ (ç¡¬é“¾æ¥)
â””â”€â”€ training.log
```

### æ¢å¤è®­ç»ƒ

å¦‚æœè®­ç»ƒè¢«ä¸­æ–­ï¼Œç»§ç»­ä»æœ€æ–°æ£€æŸ¥ç‚¹:

```bash
# 1. ç¼–è¾‘è„šæœ¬æ·»åŠ  resume å‚æ•°
# åœ¨ train.py è°ƒç”¨å‰æ·»åŠ :
--resume_from_checkpoint ./outputs/fantasy_world_stage1/latest.safetensors

# 2. é‡æ–°è¿è¡Œè„šæœ¬
bash examples/wanvideo/model_training/full/train_fantasy_world_stage1.sh
```

### æ£€æŸ¥ç‚¹éªŒè¯

```python
# verify_checkpoint.py
import torch
import safetensors.torch as sf

checkpoint_path = "outputs/fantasy_world_stage1/step-20000.safetensors"

# åŠ è½½æ£€æŸ¥ç‚¹
state_dict = sf.load_file(checkpoint_path)

print(f"æ£€æŸ¥ç‚¹å¤§å°: {len(state_dict)} ä¸ªå¼ é‡")
print(f"æ–‡ä»¶å¤§å°: {sf.safe_open(checkpoint_path, framework='pt').metadata()}")

# ç»Ÿè®¡å‚æ•°
total_params = sum(p.numel() for p in state_dict.values())
print(f"æ€»å‚æ•°: {total_params / 1e6:.0f}M")

# æ£€æŸ¥ key åç§°
print("\nå‰ 10 ä¸ª key:")
for key in list(state_dict.keys())[:10]:
    shape = state_dict[key].shape
    print(f"  {key}: {shape}")

print("\nâœ… æ£€æŸ¥ç‚¹æœ‰æ•ˆ")
```

### æ£€æŸ¥ç‚¹æ¸…ç†

```bash
# ä¿ç•™é‡è¦æ£€æŸ¥ç‚¹ï¼Œåˆ é™¤ä¸­é—´çš„
rm outputs/fantasy_world_stage1/step-{1000..19000}.safetensors

# åªä¿ç•™æœ€å 5 ä¸ª
ls -t outputs/fantasy_world_stage1/step-*.safetensors | tail -n +6 | xargs rm
```

---

## ğŸ“ˆ è®­ç»ƒæµç¨‹æ€»ç»“

### Timeline

```
Day 1-2: ç¯å¢ƒæ­å»º + æ•°æ®å‡†å¤‡
Day 3-4: Stage 1 è®­ç»ƒ (36 hours)
Day 5-10: Stage 2 è®­ç»ƒ (144 hours, 6 days)
Day 11: éªŒè¯å’Œæµ‹è¯•

æ€»è®¡: 10-11 å¤© (åŒ…æ‹¬ç­‰å¾… GPU çš„æ—¶é—´)
```

### æ£€æŸ¥æ¸…å•

**å¼€å§‹ Stage 1 å‰:**
- [ ] ç¯å¢ƒå˜é‡é…ç½®æ­£ç¡®
- [ ] æ•°æ®é›†éªŒè¯é€šè¿‡
- [ ] GPU æ•°é‡å’Œæ˜¾å­˜å……è¶³
- [ ] Stage 1 è„šæœ¬é…ç½®ä¿®æ”¹å®Œæˆ
- [ ] æœ‰å¤‡ä»½è®¡åˆ’

**Stage 1 è¿è¡Œä¸­:**
- [ ] Loss æ­£å¸¸ä¸‹é™
- [ ] GPU åˆ©ç”¨ç‡ > 90%
- [ ] æ— é”™è¯¯æˆ–è­¦å‘Šæ¶ˆæ¯
- [ ] æ£€æŸ¥ç‚¹å®šæœŸä¿å­˜

**Stage 1 å®Œæˆå:**
- [ ] Step-20000 æ£€æŸ¥ç‚¹å­˜åœ¨
- [ ] éªŒè¯äº†æ¨ç†åŠŸèƒ½
- [ ] å¤‡ä»½äº† Stage 1 æ£€æŸ¥ç‚¹

**å¼€å§‹ Stage 2 å‰:**
- [ ] Stage 1 æ£€æŸ¥ç‚¹è·¯å¾„æ­£ç¡®
- [ ] Stage 2 è„šæœ¬é…ç½®ä¿®æ”¹å®Œæˆ
- [ ] æ•°æ®é›†ä»ç„¶å¯ç”¨
- [ ] GPU å†…å­˜é‡æ–°æ¸…ç©º

**Stage 2 è¿è¡Œä¸­:**
- [ ] åˆå§‹ loss ä» Stage 1 ç»§æ‰¿ (è¾ƒä½å€¼)
- [ ] Loss ç»§ç»­ä¸‹é™
- [ ] ç›‘æ§å‡ ä½•äº¤äº’æ˜¯å¦æ”¹è¿›

**Stage 2 å®Œæˆå:**
- [ ] æœ€ç»ˆæ£€æŸ¥ç‚¹ç”Ÿæˆ
- [ ] å®Œæ•´éªŒè¯æ¨ç†
- [ ] å¤‡ä»½æœ€ç»ˆæ¨¡å‹

---

## ğŸ¯ ä¸‹ä¸€æ­¥

å®Œæˆ Stage 2 è®­ç»ƒå:

1. âœ… æŸ¥çœ‹ [æ¨ç†æŒ‡å—](./INFERENCE_GUIDE.md) ä½¿ç”¨æ¨¡å‹
2. âœ… å‚è€ƒ [æ•…éšœæ’æŸ¥](./TROUBLESHOOTING.md) è§£å†³é—®é¢˜
3. âœ… æŸ¥é˜… [æŠ€æœ¯æ·±å…¥](./TECHNICAL_DEEP_DIVE.md) ç†è§£è®¾è®¡

**æ­å–œï¼** ä½ ç°åœ¨æ‹¥æœ‰ä¸€ä¸ªå®Œæ•´çš„ Fantasy World æ¨¡å‹ï¼ ğŸ‰
