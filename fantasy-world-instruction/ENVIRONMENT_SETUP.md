# ğŸ”§ ç¯å¢ƒä¸å‰æœŸå‡†å¤‡å®Œæ•´æŒ‡å—

è¯¦ç»†çš„ç¯å¢ƒé…ç½®å’Œé¡¹ç›®å®‰è£…æ­¥éª¤ã€‚

---

## ğŸ“‹ ç›®å½•

1. [ç³»ç»Ÿéœ€æ±‚](#ç³»ç»Ÿéœ€æ±‚)
2. [Python ç¯å¢ƒé…ç½®](#python-ç¯å¢ƒé…ç½®)
3. [CUDA ä¸ GPU è®¾ç½®](#cuda-ä¸-gpu-è®¾ç½®)
4. [é¡¹ç›®å®‰è£…](#é¡¹ç›®å®‰è£…)
5. [ç¯å¢ƒéªŒè¯](#ç¯å¢ƒéªŒè¯)
6. [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)

---

## ğŸ’» ç³»ç»Ÿéœ€æ±‚

### æ“ä½œç³»ç»Ÿ

- **æ¨è**: Ubuntu 20.04 LTS æˆ–æ›´é«˜ç‰ˆæœ¬
- **æ”¯æŒ**: CentOS 8+, Debian 11+
- **ä¹Ÿå¯**: Windows (WSL2) æˆ– macOS (é™æ¨ç†)

### ç¡¬ä»¶

#### æœ€ä½è¦æ±‚ (ä»…æ¨ç†)

- CPU: Intel Xeon æˆ–åŒç­‰çº§ (8+ æ ¸)
- GPU: ä»»ä½•æ”¯æŒ CUDA çš„ NVIDIA GPU (12GB+ æ˜¾å­˜)
  - RTX 3080/3090
  - RTX 4090
  - A6000 (48GB)
  - H100 (80GB)
- RAM: 32GB
- å­˜å‚¨: 50GB (æ¨¡å‹ + ä¸´æ—¶æ–‡ä»¶)

#### æ¨èé…ç½® (è®­ç»ƒ)

- CPU: 128 æ ¸æˆ–æ›´å¤š
- GPU: 8 Ã— H20 (40GB) æˆ– A100 (80GB)
- RAM: 512GB
- å­˜å‚¨: 1TB+ SSD (å¿«é€Ÿå­˜å‚¨)
- ç½‘ç»œ: 100Mbps+ (ç”¨äºä¸‹è½½æƒé‡)

### è½¯ä»¶æ ˆ

```
æ“ä½œç³»ç»Ÿ (Linux)
    â†“
Python 3.9+ â­
    â†“
CUDA 11.8+ (ä»… NVIDIA GPU)
    â†“
PyTorch 2.0+
    â†“
DiffSynth-Studio + Fantasy World â­
```

---

## ğŸ Python ç¯å¢ƒé…ç½®

### æ­¥éª¤ 1: æ£€æŸ¥ Python ç‰ˆæœ¬

```bash
python3 --version

# æœŸæœ›è¾“å‡º: Python 3.9.x æˆ–æ›´é«˜
```

å¦‚æœæ²¡æœ‰ Python 3.9+:

```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install python3.9 python3.9-venv python3.9-dev

# è®¾ç½®ä¸ºé»˜è®¤
sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.9 1
```

### æ­¥éª¤ 2: åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ (æ¨è)

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.9 -m venv ~/envs/fantasy_world

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source ~/envs/fantasy_world/bin/activate

# éªŒè¯
python --version  # åº”è¯¥æ˜¾ç¤º Python 3.9.x
which python      # åº”è¯¥åœ¨ ~/envs/fantasy_world/bin/python
```

**æ·»åŠ åˆ° shell profile** (å¯é€‰ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨):

```bash
echo 'alias fw_env="source ~/envs/fantasy_world/bin/activate"' >> ~/.bashrc
source ~/.bashrc

# ç°åœ¨å¯ä»¥ç›´æ¥ä½¿ç”¨
fw_env
```

### æ­¥éª¤ 3: å‡çº§ pip

```bash
pip install --upgrade pip setuptools wheel

# éªŒè¯
pip --version
```

### æ­¥éª¤ 4: é…ç½® pip æº (å¯é€‰ï¼ŒåŠ é€Ÿä¸‹è½½)

åˆ›å»º `~/.pip/pip.conf`:

```ini
[global]
index-url = https://pypi.tuna.tsinghua.edu.cn/simple
# æˆ–å…¶ä»–é•œåƒ:
# https://mirrors.aliyun.com/pypi/simple/
# https://pypi.org/simple/
```

---

## ğŸ® CUDA ä¸ GPU è®¾ç½®

### æ£€æŸ¥ NVIDIA é©±åŠ¨

```bash
nvidia-smi

# æœŸæœ›è¾“å‡º:
# +-----------------------------------+
# | NVIDIA-SMI 535.00    Driver Version: 535.00 |
# | GPU  Name         Persistence-M| Bus-Id |
# |   0  NVIDIA H20 ... |  GPU-UUID  |
# +-----------------------------------+
```

å¦‚æœæ²¡æœ‰é©±åŠ¨:

```bash
# Ubuntu 22.04
sudo apt-get update
sudo apt-get install nvidia-driver-535

# é‡å¯
sudo reboot
```

### å®‰è£… CUDA Toolkit

```bash
# æ£€æŸ¥å½“å‰ CUDA ç‰ˆæœ¬
nvcc --version

# å¦‚æœæ²¡æœ‰æˆ–ç‰ˆæœ¬è¿‡ä½ï¼Œä¸‹è½½å®‰è£…
# https://developer.nvidia.com/cuda-11-8-0-download-archive

# Ubuntu 22.04 ç¤ºä¾‹:
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run --silent --driver --toolkit

# æ·»åŠ åˆ° PATH
echo 'export PATH=$PATH:/usr/local/cuda-11.8/bin' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.8/lib64' >> ~/.bashrc
source ~/.bashrc
```

### éªŒè¯ CUDA è®¾ç½®

```bash
# æ£€æŸ¥ nvcc ç¼–è¯‘å™¨
nvcc --version

# æ£€æŸ¥æ˜¯å¦å¯ç”¨
python << 'EOF'
import torch
print("CUDA å¯ç”¨:", torch.cuda.is_available())
print("CUDA ç‰ˆæœ¬:", torch.version.cuda)
print("GPU æ•°é‡:", torch.cuda.device_count())
if torch.cuda.is_available():
    print("GPU åç§°:", torch.cuda.get_device_name(0))
    print("æ˜¾å­˜å¤§å°:", torch.cuda.get_device_properties(0).total_memory / 1e9, "GB")
EOF
```

**æœŸæœ›è¾“å‡º**:
```
CUDA å¯ç”¨: True
CUDA ç‰ˆæœ¬: 11.8
GPU æ•°é‡: 8
GPU åç§°: NVIDIA H20 Tensor Core GPU
æ˜¾å­˜å¤§å°: 40.0 GB
```

---

## ğŸ“¦ é¡¹ç›®å®‰è£…

### æ­¥éª¤ 1: è¿›å…¥é¡¹ç›®ç›®å½•

```bash
cd /ML-vePFS/research_gen/jmy/jmy_ws/Diffsynth-fantasy-world
pwd  # éªŒè¯ä½ç½®
```

### æ­¥éª¤ 2: å®‰è£…ä¾èµ–

```bash
# æ–¹æ³• A: å¼€å‘æ¨¡å¼ (æ¨èï¼Œæ”¯æŒä»£ç ä¿®æ”¹)
pip install -e .

# æ–¹æ³• B: ç”Ÿäº§æ¨¡å¼ (å¦‚æœä»…ä½¿ç”¨ï¼Œä¸ä¿®æ”¹ä»£ç )
pip install .
```

**å®‰è£…ä¼šè‡ªåŠ¨ä¸‹è½½å¹¶å®‰è£…**:
- torch
- torchvision
- diffusers
- transformers
- safetensors
- ç­‰å…¶ä»–ä¾èµ–

è¿™é€šå¸¸éœ€è¦ 5-10 åˆ†é’Ÿã€‚

### æ­¥éª¤ 3: ä¸‹è½½æ¨¡å‹æƒé‡ (é¦–æ¬¡)

```bash
# è‡ªåŠ¨åœ¨ç¬¬ä¸€æ¬¡æ¨ç†æ—¶ä¸‹è½½ï¼Œæˆ–æ‰‹åŠ¨ä¸‹è½½
python << 'EOF'
from diffsynth import WanVideoPipeline

# è¿™ä¼šä¸‹è½½ ~5GB çš„æ¨¡å‹æƒé‡
pipe = WanVideoPipeline.from_pretrained(
    "PAI/Wan2.1-Fun-V1.1-1.3B-Control-Camera"
)
print("âœ… æ¨¡å‹æƒé‡å·²ä¸‹è½½")
EOF
```

æƒé‡ä¿å­˜ä½ç½®: `~/.cache/huggingface/hub/`

### æ­¥éª¤ 4: (å¯é€‰) å®‰è£… cuDNN

```bash
# CUDA 11.8 å¯¹åº” cuDNN 8.x
# ä» NVIDIA å®˜ç½‘ä¸‹è½½ (éœ€è¦è´¦æˆ·): https://developer.nvidia.com/cudnn

# è§£å‹å¹¶å¤åˆ¶åˆ° CUDA ç›®å½•
tar -xzvf cudnn-linux-x86_64-8.*.tar.xz
sudo cp cudnn-linux-x86_64-8.*/include/cudnn*.h /usr/local/cuda/include/
sudo cp cudnn-linux-x86_64-8.*/lib/x86_64-linux-gnu/libcudnn* /usr/local/cuda/lib64/
sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*
```

---

## âœ… ç¯å¢ƒéªŒè¯

### å®Œæ•´éªŒè¯è„šæœ¬

```bash
cat > verify_environment.py << 'EOF'
#!/usr/bin/env python
import sys

print("=" * 60)
print("Fantasy World ç¯å¢ƒéªŒè¯")
print("=" * 60)

# 1. Python ç‰ˆæœ¬
import sys
print(f"âœ“ Python ç‰ˆæœ¬: {sys.version}")
assert sys.version_info >= (3, 8), "Python ç‰ˆæœ¬å¤ªä½ï¼Œéœ€è¦ 3.8+"

# 2. PyTorch
try:
    import torch
    print(f"âœ“ PyTorch: {torch.__version__}")
    print(f"âœ“ CUDA å¯ç”¨: {torch.cuda.is_available()}")
    if torch.cuda.is_available():
        print(f"âœ“ CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        print(f"âœ“ GPU æ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            props = torch.cuda.get_device_properties(i)
            print(f"  - GPU {i}: {props.name} ({props.total_memory / 1e9:.0f}GB)")
except ImportError:
    print("âœ— PyTorch æœªå®‰è£…")
    sys.exit(1)

# 3. diffsynth
try:
    import diffsynth
    print(f"âœ“ DiffSynth: å·²å®‰è£…")
    from diffsynth import WanVideoPipeline
    print(f"âœ“ WanVideoPipeline: å¯ç”¨")
except ImportError as e:
    print(f"âœ— DiffSynth: {e}")
    sys.exit(1)

# 4. Fantasy World æ¨¡å—
try:
    from diffsynth.core.data.fantasy_world_dataset import FantasyWorldDataset
    print(f"âœ“ FantasyWorldDataset: å¯ç”¨")
except ImportError as e:
    print(f"âš  FantasyWorldDataset: {e}")

# 5. å…¶ä»–å…³é”®ä¾èµ–
critical_packages = [
    'numpy', 'PIL', 'cv2', 'safetensors', 'transformers'
]

for pkg_name in critical_packages:
    try:
        __import__(pkg_name)
        print(f"âœ“ {pkg_name}: å·²å®‰è£…")
    except ImportError:
        print(f"âœ— {pkg_name}: æœªå®‰è£…")

print("=" * 60)
print("âœ… ç¯å¢ƒéªŒè¯å®Œæˆï¼")
print("=" * 60)
EOF

python verify_environment.py
```

### å¿«é€ŸéªŒè¯

```bash
# æœ€å¿«çš„éªŒè¯æ–¹æ³•
python -c "from diffsynth import WanVideoPipeline; print('âœ… ç¯å¢ƒæ­£å¸¸')"
```

### éªŒè¯ GPU å¯ç”¨æ€§

```bash
python << 'EOF'
import torch
from torch.utils.data import DataLoader

# åˆ›å»ºæµ‹è¯•å¼ é‡
x = torch.randn(2, 3, 224, 224).cuda()
print(f"âœ“ å¼ é‡ä½ç½®: {x.device}")

# æµ‹è¯•åŸºæœ¬æ“ä½œ
y = torch.nn.functional.relu(x)
z = y.mean()
print(f"âœ“ å¼ é‡æ“ä½œæˆåŠŸ")

print("âœ… GPU å¯ç”¨ä¸”æ­£å¸¸å·¥ä½œ")
EOF
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: "ModuleNotFoundError: No module named 'diffsynth'"

**ç—‡çŠ¶**:
```
Traceback (most recent call last):
  File "train.py", line 1, in <module>
    from diffsynth import ...
ModuleNotFoundError: No module named 'diffsynth'
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥æ˜¯å¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­
which python

# 2. é‡æ–°å®‰è£…
pip install -e /ML-vePFS/research_gen/jmy/jmy_ws/Diffsynth-fantasy-world

# 3. æ¸…é™¤ç¼“å­˜åé‡è¯•
pip cache purge
pip install -e .

# 4. æ£€æŸ¥ PYTHONPATH
export PYTHONPATH="/ML-vePFS/research_gen/jmy/jmy_ws/Diffsynth-fantasy-world:$PYTHONPATH"
python -c "import diffsynth"
```

### é—®é¢˜ 2: "CUDA out of memory"

**ç—‡çŠ¶**:
```
RuntimeError: CUDA out of memory. Tried to allocate ...
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ¸…é™¤ GPU ç¼“å­˜
python << 'EOF'
import torch
torch.cuda.empty_cache()
EOF

# 2. æ£€æŸ¥å“ªäº›è¿›ç¨‹å ç”¨ GPU
nvidia-smi

# 3. æ€æ­»å ç”¨è¿›ç¨‹
kill <PID>

# 4. è°ƒæ•´è®­ç»ƒå‚æ•° (è§ TRAINING_GUIDE.md)
```

### é—®é¢˜ 3: "CUDA not available"

**ç—‡çŠ¶**:
```
torch.cuda.is_available() returns False
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥é©±åŠ¨
nvidia-smi

# 2. æ£€æŸ¥ CUDA Toolkit
nvcc --version

# 3. é‡æ–°å®‰è£… PyTorchï¼ˆé’ˆå¯¹ä½ çš„ CUDA ç‰ˆæœ¬ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 4. éªŒè¯
python -c "import torch; print(torch.cuda.is_available())"
```

### é—®é¢˜ 4: æ¨¡å‹æƒé‡ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**:
```
huggingface_hub.utils._errors.RepositoryNotFoundError
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. æ£€æŸ¥ç½‘ç»œè¿æ¥
ping huggingface.co

# 2. è®¾ç½® HF é•œåƒ (ä¸­å›½ç”¨æˆ·)
export HF_ENDPOINT=https://huggingface.co
export HF_HOME=~/.cache/huggingface

# 3. æ‰‹åŠ¨ä¸‹è½½æƒé‡ (å¦‚æœè‡ªåŠ¨ä¸‹è½½å¤±è´¥)
# ä» https://huggingface.co/PAI/Wan2.1-Fun-V1.1-1.3B-Control-Camera ä¸‹è½½

# 4. æŒ‡å®šæœ¬åœ°è·¯å¾„
pipe = WanVideoPipeline.from_pretrained(
    "/path/to/local/model"
)
```

### é—®é¢˜ 5: pip ä¸‹è½½å¾ˆæ…¢

**ç—‡çŠ¶**:
```
Collecting torch...
  Downloading torch-2.0.1+cu118-cp39-cp39-linux_x86_64.whl (2.0GB)
  0% |                           | 50.0MB / 2.0GB [00:00<...]
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# 1. ä½¿ç”¨å›½å†…é•œåƒ (ä¸­å›½ç”¨æˆ·)
pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple

# 2. æˆ–å•æ¬¡ä½¿ç”¨
pip install torch -i https://pypi.aliyun.com/simple

# 3. ä½¿ç”¨æ¸…åæº (ä¸€èˆ¬æœ€å¿«)
pip install torch -i https://mirrors.tsinghua.edu.cn/pypi/web/simple

# 4. æ£€æŸ¥é•œåƒé…ç½®
pip config show
```

### é—®é¢˜ 6: è™šæ‹Ÿç¯å¢ƒæ¿€æ´»å¤±è´¥

**ç—‡çŠ¶**:
```
command not found: activate
```

**è§£å†³æ–¹æ¡ˆ**:

```bash
# ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ¿€æ´»è„šæœ¬
source ~/envs/fantasy_world/bin/activate  # Linux/macOS
# æˆ–
~/envs/fantasy_world/Scripts/activate     # Windows (å¸¦.bat)

# éªŒè¯æ¿€æ´»æˆåŠŸ
echo $VIRTUAL_ENV  # åº”è¯¥æ˜¾ç¤ºè™šæ‹Ÿç¯å¢ƒè·¯å¾„
```

---

## ğŸ“‹ ç¯å¢ƒé…ç½®æ¸…å•

åœ¨å¼€å§‹é¡¹ç›®å‰ï¼Œç¡®ä¿å®Œæˆæ‰€æœ‰é¡¹ç›®ï¼š

```
ç¯å¢ƒæ£€æŸ¥æ¸…å•:
â˜ Python ç‰ˆæœ¬ >= 3.8
â˜ NVIDIA é©±åŠ¨å·²å®‰è£…
â˜ CUDA Toolkit å·²å®‰è£… (11.8+)
â˜ PyTorch å·²å®‰è£…å¹¶æ”¯æŒ CUDA
â˜ diffsynth å·²å®‰è£… (pip install -e .)
â˜ æ‰€æœ‰ä¾èµ–å·²å®‰è£… (pip list æ£€æŸ¥)
â˜ GPU å¯ç”¨ (nvidia-smi æˆ– torch.cuda.is_available())
â˜ æ¨¡å‹æƒé‡å·²ä¸‹è½½ (~/.cache/huggingface)
â˜ è™šæ‹Ÿç¯å¢ƒå·²åˆ›å»ºå¹¶æ¿€æ´»

ç¡¬ä»¶æ£€æŸ¥æ¸…å•:
â˜ GPU æ˜¾å­˜å……è¶³ (>= 12GB)
â˜ ç¡¬ç›˜ç©ºé—´å……è¶³ (>= 50GB)
â˜ ç½‘ç»œè¿æ¥æ­£å¸¸

éªŒè¯æ£€æŸ¥æ¸…å•:
â˜ python -c "import diffsynth" æˆåŠŸ
â˜ python -c "import torch; print(torch.cuda.is_available())" è¿”å› True
â˜ nvidia-smi æ˜¾ç¤º GPU ä¿¡æ¯
â˜ å¯ä»¥å¯åŠ¨è®­ç»ƒè„šæœ¬ (ä¸æŠ¥ import é”™è¯¯)
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

ç¯å¢ƒå‡†å¤‡å®Œæˆåï¼š

1. æŸ¥çœ‹ [æ•°æ®å‡†å¤‡](./DATA_PREPARATION.md) å‡†å¤‡è®­ç»ƒæ•°æ®
2. æˆ–æŸ¥çœ‹ [è®­ç»ƒæŒ‡å—](./TRAINING_GUIDE.md) å¼€å§‹è®­ç»ƒ
3. æˆ–æŸ¥çœ‹ [æ¨ç†æŒ‡å—](./INFERENCE_GUIDE.md) è¿›è¡Œæ¨ç†

---

## ğŸ“ è·å–å¸®åŠ©

å¦‚ç¯å¢ƒé—®é¢˜æ— æ³•è§£å†³ï¼š

1. æ£€æŸ¥ [æ•…éšœæ’æŸ¥](#%EF%B8%8F-æ•…éšœæ’æŸ¥) éƒ¨åˆ†
2. æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£: `/docs/`
3. æ£€æŸ¥ PyTorch å®˜æ–¹æ–‡æ¡£: https://pytorch.org/
4. æ£€æŸ¥ CUDA å®˜æ–¹æ–‡æ¡£: https://docs.nvidia.com/cuda/

ç¥ç¯å¢ƒé…ç½®é¡ºåˆ©ï¼ ğŸš€
