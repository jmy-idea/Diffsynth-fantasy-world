# Fantasy World Two-Stage Training Guide

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜ Fantasy World çš„ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥ã€‚

## ğŸ“– è®ºæ–‡ä¸­çš„è®­ç»ƒç­–ç•¥ (Section 4.3)

Fantasy World é‡‡ç”¨ä¸¤é˜¶æ®µè®­ç»ƒç­–ç•¥æ¥ç¨³å®š geometry-aware video generation çš„è®­ç»ƒè¿‡ç¨‹ï¼š

### Stage 1: Latent Bridging (æ½œåœ¨ç©ºé—´æ¡¥æ¥)

**ç›®çš„**: å°† geometry branch é€‚é…åˆ°å·²å†»ç»“çš„ video backbone ç‰¹å¾ç©ºé—´

**è®­ç»ƒé…ç½®**:
- **è®­ç»ƒæ­¥æ•°**: 20,000 steps
- **Batch Size**: 64 (global)
- **Resolution**: å¯ä»¥ä½¿ç”¨è¾ƒä½åˆ†è¾¨ç‡ä»¥æé«˜ç¨³å®šæ€§
- **å­¦ä¹ ç‡**: 1e-5 (AdamW)
- **ç¡¬ä»¶**: 64 Ã— H20 GPUs, ~36 hours

**å¯è®­ç»ƒæ¨¡å—**:
- âœ… Latent Bridge Adapter (æ˜ å°„ video features åˆ° geometry space)
- âœ… GeoDiT Blocks (18 blocks with VGGT-style attention)
- âœ… DPT Heads (depth, point, camera)
- âœ… Pose Encoder (Plucker embedding)
- âœ… Special Tokens (camera token + register tokens)

**å†»ç»“æ¨¡å—**:
- â„ï¸ Wan2.1 åŸæœ‰çš„ 30 blocks (PCB 12 + IRG 18)
- â„ï¸ Camera Adapters (Stage 2 æ‰ä¼šä½¿ç”¨)
- â„ï¸ IRG Cross-Attention (Stage 2 æ‰ä¼šä½¿ç”¨)

**å…³é”®ç‚¹**:
- è¿™ä¸€é˜¶æ®µåªè®­ç»ƒ geometry branch æ ¸å¿ƒ
- è®© geometry branch å­¦ä¼šä» frozen video features ä¸­æå–å‡ ä½•ä¿¡æ¯
- **ä¸ä½¿ç”¨** video-geometry interaction (cross-attention, camera injection)

---

### Stage 2: Unified Co-Optimization (è”åˆååŒä¼˜åŒ–)

**ç›®çš„**: å¾®è°ƒ interaction modulesï¼Œå®ç° video å’Œ geometry ç‰¹å¾çš„åŒå‘äº¤äº’

**è®­ç»ƒé…ç½®**:
- **è®­ç»ƒæ­¥æ•°**: 10,000 steps
- **Batch Size**: 112 (global)
- **Resolution**: 592Ã—336 æˆ– 336Ã—592 (full resolution)
- **å­¦ä¹ ç‡**: 1e-5 (AdamW)
- **ç¡¬ä»¶**: 112 Ã— H20 GPUs, ~144 hours
- **åˆå§‹åŒ–**: ä» Stage 1 checkpoint åŠ è½½

**å¯è®­ç»ƒæ¨¡å—**:
- âœ… **ç»§ç»­è®­ç»ƒ** Stage 1 çš„æ‰€æœ‰æ¨¡å— (latent_bridge, geo_blocks, heads, pose_enc, tokens)
- âœ… **æ–°å¢è®­ç»ƒ** IRG Bidirectional Cross-Attention (18 modules)
- âœ… **æ–°å¢è®­ç»ƒ** Camera Control Adapters (first 12 blocks)

**ä»ç„¶å†»ç»“**:
- â„ï¸ Wan2.1 åŸæœ‰çš„ 30 blocks (å§‹ç»ˆå†»ç»“)

**å…³é”®ç‚¹**:
- åœ¨ Stage 1 åŸºç¡€ä¸Šæ·»åŠ  interaction modules
- Geometry branch å·²ç» well-adaptedï¼Œç°åœ¨å­¦ä¹ åŒå‘äº¤äº’
- ä½¿ç”¨å®Œæ•´åˆ†è¾¨ç‡çš„ 81-frame clips

---

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### å‡†å¤‡æ•°æ®

ç¡®ä¿ä½ çš„æ•°æ®é›†åŒ…å«ï¼š
```
dataset/
â”œâ”€â”€ metadata.json         # æ•°æ®é›†å…ƒä¿¡æ¯
â”œâ”€â”€ videos/              # è§†é¢‘æ–‡ä»¶
â”‚   â”œâ”€â”€ sample1.mp4
â”‚   â””â”€â”€ sample2.mp4
â”œâ”€â”€ depth/               # æ·±åº¦å›¾ (Depth Anything V2)
â”‚   â”œâ”€â”€ sample1/
â”‚   â”‚   â”œâ”€â”€ frame_0000.npy  # [H, W]
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ sample2/
â”œâ”€â”€ points/              # ç‚¹äº‘ (DUSt3R)
â”‚   â”œâ”€â”€ sample1/
â”‚   â”‚   â”œâ”€â”€ frame_0000.npy  # [H, W, 3]
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ sample2/
â””â”€â”€ camera_params/       # ç›¸æœºå‚æ•° (DUSt3R + PnP)
    â”œâ”€â”€ sample1.txt      # [T, 12] world-to-camera matrices
    â””â”€â”€ sample2.txt
```

### Stage 1: Latent Bridging

```bash
cd /ML-vePFS/research_gen/jmy/jmy_ws/Diffsynth-fantasy-world

# 1. é…ç½®è®­ç»ƒè„šæœ¬
vim examples/wanvideo/model_training/full/train_fantasy_world_stage1.sh
# ä¿®æ”¹:
#   DATA_DIR="/path/to/your/fantasy_world_data"
#   CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7  # æ ¹æ®ä½ çš„GPUæ•°é‡è°ƒæ•´
#   BATCH_SIZE_PER_GPU=8  # æ ¹æ®æ˜¾å­˜è°ƒæ•´

# 2. è¿è¡Œè®­ç»ƒ
bash examples/wanvideo/model_training/full/train_fantasy_world_stage1.sh
```

**è¾“å‡º**:
- Checkpoints ä¿å­˜åœ¨ `outputs/fantasy_world_stage1/`
- æ¯ 1000 steps ä¿å­˜ä¸€æ¬¡
- æœ€ç»ˆä½¿ç”¨ `step-20000.safetensors` è¿›å…¥ Stage 2

---

### Stage 2: Unified Co-Optimization

```bash
# 1. ç¡®è®¤ Stage 1 checkpoint å­˜åœ¨
ls outputs/fantasy_world_stage1/step-20000.safetensors

# 2. é…ç½®è®­ç»ƒè„šæœ¬
vim examples/wanvideo/model_training/full/train_fantasy_world_stage2.sh
# ä¿®æ”¹:
#   DATA_DIR="/path/to/your/fantasy_world_data"
#   STAGE1_CHECKPOINT="outputs/fantasy_world_stage1/step-20000.safetensors"
#   CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
#   BATCH_SIZE_PER_GPU=14  # å…¨åˆ†è¾¨ç‡éœ€è¦æ›´å¤šæ˜¾å­˜

# 3. è¿è¡Œè®­ç»ƒ
bash examples/wanvideo/model_training/full/train_fantasy_world_stage2.sh
```

**è¾“å‡º**:
- Checkpoints ä¿å­˜åœ¨ `outputs/fantasy_world_stage2/`
- æœ€ç»ˆæ¨¡å‹: `step-10000.safetensors`

---

## ğŸ“Š å¯è®­ç»ƒå‚æ•°å¯¹æ¯”

| Module | Parameters | Stage 1 | Stage 2 |
|--------|-----------|---------|---------|
| **Wan2.1 Blocks** (PCB 12 + IRG 18) | ~1616M | â„ï¸ Frozen | â„ï¸ Frozen |
| **Latent Bridge Adapter** | ~5M | âœ… Train | âœ… Train |
| **GeoDiT Blocks** (18 blocks) | ~900M | âœ… Train | âœ… Train |
| **DPT Heads** (depth, point, camera) | ~50M | âœ… Train | âœ… Train |
| **Pose Encoder** | ~1M | âœ… Train | âœ… Train |
| **Special Tokens** (camera + register) | ~0.01M | âœ… Train | âœ… Train |
| **Camera Adapters** (12 modules) | ~30M | â„ï¸ Frozen | âœ… Train |
| **IRG Cross-Attention** (18 modules) | ~200M | â„ï¸ Frozen | âœ… Train |
| **Total Trainable** | - | ~956M | ~1186M |

---

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### Latent Bridge Adapter

```python
self.latent_bridge = LatentBridgeAdapter(
    dim=model_dim,           # 1536 for Wan2.1-1.3B
    num_heads=8,
    ffn_dim=model_dim * 4,
    num_layers=2             # Lightweight: only 2 layers
)
```

- æ¥æ”¶ split_layer (block 12) çš„è¾“å‡º
- æ˜ å°„åˆ° geometry-aligned latent space
- è¾“å…¥ç»™ GeoDiT blocks

### GeoDiT Blocks

- åŸºäº VGGT æ¶æ„ (Global + Frame attention)
- 18 blocks (å¯¹åº” IRG çš„ 18 layers)
- ä» 4 ä¸ªä¸­é—´å±‚æå–ç‰¹å¾ç»™ DPT heads

### Camera Adapters

```python
camera_adapters[i] = Sequential(
    SiLU(),
    Linear(dim, dim)
)
```

- é¢„æµ‹ shift Î²áµ¢ (not full AdaLN)
- æ³¨å…¥åˆ° video branch: fáµ¢ = fáµ¢â‚‹â‚ + Î²áµ¢
- åªåº”ç”¨äºå‰ 12 blocks (PCB)

### IRG Cross-Attention

```python
self.irg_cross_attns = ModuleList([
    MMBiCrossAttention(dim, num_heads) 
    for _ in range(18)  # One per IRG block
])
```

- Bidirectional cross-attention
- Video features â†” Geometry features
- åœ¨æ¯ä¸ª IRG block ååº”ç”¨

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆéœ€è¦ä¸¤é˜¶æ®µè®­ç»ƒï¼Ÿ

**A**: ç›´æ¥è”åˆè®­ç»ƒæ‰€æœ‰æ¨¡å—ä¼šå¯¼è‡´ï¼š
- Geometry branch å­¦ä¸åˆ°æœ‰æ•ˆç‰¹å¾ (video features ä¸€ç›´åœ¨å˜)
- Training instability (gradient conflicts)
- Poor convergence

ä¸¤é˜¶æ®µç­–ç•¥ï¼š
1. å…ˆè®© geometry branch é€‚é…åˆ° frozen video features
2. å†å¼•å…¥ interactionï¼Œå¾®è°ƒåŒå‘äº¤äº’

### Q2: Stage 1 å¯ä»¥ç”¨æ›´å°‘çš„ steps å—ï¼Ÿ

**A**: å¯ä»¥ï¼Œä½†å»ºè®®è‡³å°‘ 10K stepsã€‚è®ºæ–‡ç”¨ 20K steps æ˜¯ä¸ºäº†å……åˆ†æ”¶æ•›ã€‚
å¯ä»¥ç›‘æ§ geometry loss (depth, point, camera) æ¥åˆ¤æ–­æ˜¯å¦æ”¶æ•›ã€‚

### Q3: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

**è°ƒæ•´ batch size**:
```bash
# Stage 1: 64 global batch size
BATCH_SIZE_PER_GPU=8  # 8 GPUs â†’ 64
# å¦‚æœæ˜¾å­˜ä¸è¶³:
BATCH_SIZE_PER_GPU=4  # 8 GPUs â†’ 32
# å¢åŠ  gradient accumulation è¡¥å¿:
GRADIENT_ACCUMULATION=2  # Effective batch size = 32 * 2 = 64
```

**é™ä½åˆ†è¾¨ç‡** (Stage 1 only):
```bash
HEIGHT=288  # ä» 336 é™ä½
WIDTH=512   # ä» 592 é™ä½
```

**å‡å°‘ frames**:
```bash
NUM_FRAMES=41  # ä» 81 é™ä½åˆ° 41
```

### Q4: å¦‚ä½•éªŒè¯ Stage 1 è®­ç»ƒæ•ˆæœï¼Ÿ

**ç›‘æ§æŒ‡æ ‡**:
- `loss/depth_loss`: åº”è¯¥é™åˆ° < 0.1
- `loss/point_loss`: åº”è¯¥é™åˆ° < 0.5
- `loss/camera_loss`: åº”è¯¥é™åˆ° < 0.05

**å¯è§†åŒ–** (æ¨è):
åŠ è½½ Stage 1 checkpointï¼Œåœ¨éªŒè¯é›†ä¸Šï¼š
1. å¯è§†åŒ–é¢„æµ‹çš„ depth maps
2. å¯è§†åŒ–é¢„æµ‹çš„ point clouds
3. å¯¹æ¯” GT å’Œé¢„æµ‹çš„ camera trajectories

### Q5: Stage 2 å¿…é¡»ä» Stage 1 checkpoint åŠ è½½å—ï¼Ÿ

**A**: æ˜¯çš„ï¼Œå¿…é¡»ã€‚Stage 2 ä¾èµ– Stage 1 è®­ç»ƒå¥½çš„ geometry branchã€‚
è„šæœ¬ä¼šè‡ªåŠ¨æ£€æŸ¥ `STAGE1_CHECKPOINT` æ˜¯å¦å­˜åœ¨ã€‚

---

## ğŸ“ æ–‡ä»¶ç»“æ„

```
examples/wanvideo/model_training/full/
â”œâ”€â”€ train_fantasy_world_stage1.sh      # Stage 1 è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_fantasy_world_stage2.sh      # Stage 2 è®­ç»ƒè„šæœ¬
â””â”€â”€ TWO_STAGE_TRAINING_GUIDE.md        # æœ¬æ–‡æ¡£

outputs/
â”œâ”€â”€ fantasy_world_stage1/              # Stage 1 è¾“å‡º
â”‚   â”œâ”€â”€ step-1000.safetensors
â”‚   â”œâ”€â”€ step-2000.safetensors
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ step-20000.safetensors         # â†’ Stage 2 input
â””â”€â”€ fantasy_world_stage2/              # Stage 2 è¾“å‡º
    â”œâ”€â”€ step-1000.safetensors
    â”œâ”€â”€ ...
    â””â”€â”€ step-10000.safetensors         # Final model
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

è®­ç»ƒå®Œæˆåï¼Œä½¿ç”¨æœ€ç»ˆæ¨¡å‹è¿›è¡Œæ¨ç†ï¼š

```python
from diffsynth import WanVideoPipeline

# åŠ è½½ Stage 2 final checkpoint
pipe = WanVideoPipeline.from_pretrained(
    model_configs=[
        {"model_path": "outputs/fantasy_world_stage2/step-10000.safetensors"}
    ]
)

# Enable Fantasy World mode
pipe.dit.enable_fantasy_world_mode(training_stage="stage2")

# ç”Ÿæˆè§†é¢‘ with camera control
video = pipe(
    prompt="A serene underwater scene with swimming fish",
    pose_file_path="camera_trajectories/orbit_360deg.txt",
    num_frames=81,
    height=592,
    width=336,
)
```

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

- Fantasy World Paper: [arXiv:2501.XXXXX]
- Wan2.1 Model: [HuggingFace/PAI/Wan2.1-Fun-V1.1-1.3B]
- VGGT Architecture: [arXiv:2407.XXXXX]
- DUSt3R: [arXiv:2312.14132]
- Depth Anything V2: [arXiv:2406.09414]

---

**ç¥è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹:
- [SETUP_GUIDE.md](../../docs/SETUP_GUIDE.md)
- [ROPE_FIX_EXPLANATION.md](../../docs/ROPE_FIX_EXPLANATION.md)
- [DTYPE_FIX_EXPLANATION.md](../../docs/DTYPE_FIX_EXPLANATION.md)
